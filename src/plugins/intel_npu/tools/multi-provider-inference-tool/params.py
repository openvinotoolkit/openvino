#!/usr/bin/env python

#
# Copyright (C) 2025 Intel Corporation
# SPDX-License-Identifier: Apache 2.0
#

from collections import defaultdict
from collections.abc import Mapping
import copy
import enum
import hashlib
import json
import os
from pathlib import Path

BatchedImage = list


def splitOnBatch(files_list) -> BatchedImage:
    return files_list.split("|")


def if_file(file_path):
    return os.path.isfile(file_path)


def is_directory(directory_path):
    return os.path.isdir(directory_path)

def shape_to_list(shape):
    ret = shape
    if isinstance(shape, (str, bytes)):
        ret = json.loads(shape)
    return ret

def layout_to_str(layout):
    ret = layout
    if isinstance(layout, list):
        ret = "".join(layout)
    return ret

class FilesStorage:
    class InputSourceFileType(enum.IntEnum):
        image = 0
        bin = 1

    source_file_types = [ name for name, _ in InputSourceFileType.__members__.items()]
    source_description = f'''It is possible to specify three types of inputs:
two from the list {source_file_types} and a path to a JSON file contained inputs description."
Please look at the required JSON formats:\n
1) If you want to specify files as "{InputSourceFileType.image.name}", please use the following format:''' + '''
"{
    \\"my_model_input\\": {
        \\"files\\": [
            image_path_0,
            image_path_1,
            ...
        ],
        \\"type\\":\\"''' + InputSourceFileType.image.name + '''\\"
    }
}"
\n2) If you want to specify files as "''' + InputSourceFileType.image.name + '''", and convert them to different shape or data type please add a "convert" section and use the following format:''' + '''
"{
    \\"my_model_input\\": {
        \\"files\\": [
            image_path_0,
            image_path_1,
            ...
        ],
        \\"type\\":\\"''' + InputSourceFileType.image.name + '''\\",
        \\"convert\\":{\\"shape\\":\\"[1,3,372,500]\\", \\"element_type\\":\\"float32\\"}
    }
}"

\n3) If you want to specify files as "''' + InputSourceFileType.bin.name + '''", please use the following format:''' + '''
"{
    \\"my_model_input.1\\": {
        \\"files\\": [
            blob_path_0,
            blob_path_1,
            ...
        ],
        \\"type\\": \\"''' + InputSourceFileType.bin.name + '''\\",
        \\"shape\\": [1, 3, 299, 299],
        \\"layout\\": \\"NCHW\\",
        \\"element_type\": numpy.dtype.name
    }
}"
\n4) Or just specify a path to input descriptions in JSON files, which
are automatically generated by the tool every time it finishes inference.
Location of these files usually described by the paths:

    "<provider_name>/<model_name>/input_img.json"
or
    "<provider_name>/<model_name>/input_dump_data.json"

'''
    source_json_schema_allowable = {InputSourceFileType.image.name: {"files"},
                                    InputSourceFileType.bin.name  : {"files", "element_type", "shape"}}
    source_json_schema_forbidden = {InputSourceFileType.image.name: {"shape", "element_type"},
                                    InputSourceFileType.bin.name  : {"convert"}}
    def __init__(self):
        self.files_per_input_json = {}

    def __validate_image__(data):
        if "convert" in data.keys():
            if "shape" in data["convert"].keys():
                data["convert"]["shape"] = shape_to_list(data["convert"]["shape"])
            if "layout" in data["convert"].keys():
                data["convert"]["layout"] = layout_to_str(data["convert"]["layout"])

    def __validate_bin__(data):
        if "shape" in data.keys():
            data["shape"] = shape_to_list(data["shape"])
        if "layout" in data.keys():
            data["layout"] = layout_to_str(data["layout"])

    def __validate__(files_per_input_json) :
        for i,d in files_per_input_json.items():
            if "type" not in d.keys():
                raise RuntimeError(f"FilesStorage validity failed: important field \"type\" is absent for input source: \"{i}\": {d}\n. Please specify a one from: {FilesStorage.source_file_types}")
            if d["type"] not in FilesStorage.source_file_types:
                raise RuntimeError(f"FilesStorage validity failed: unsupported \"type\" value: \"{d['type']}\" for input source: \"{i}\": {d}\n. Please specify a correct one from: {FilesStorage.source_file_types}")
            if not FilesStorage.source_json_schema_allowable[d["type"]].issubset(set(d.keys())):
                raise RuntimeError(f"FilesStorage validity failed: some important fields: {FilesStorage.source_json_schema_allowable[d['type']]} are absent in the description of input source: \"{i}\": {d}\n. Please specify them all")
            if len(FilesStorage.source_json_schema_forbidden[d["type"]] & (set(d.keys()))):
                raise RuntimeError(f"FilesStorage validity failed: These fields: {FilesStorage.source_json_schema_forbidden[d['type']]} are not allowed in the description of input source: \"{i}\": {d}\n. Please remove them all.")

            if d["type"] == FilesStorage.source_file_types[int(FilesStorage.InputSourceFileType.image)]:
                FilesStorage.__validate_image__(d)
            if d["type"] == FilesStorage.source_file_types[int(FilesStorage.InputSourceFileType.bin)]:
                FilesStorage.__validate_bin__(d)

    @staticmethod
    def __parse_json_obj__(json_data):
        return_json_data = {}
        for io_name, io_data in json_data.items():
            if isinstance(io_data, Mapping):
                return_json_data[io_name] = io_data
                if "type" not in io_data.keys():
                    return_json_data[io_name]["type"] = FilesStorage.InputSourceFileType.bin.name
            else:
                return_json_data[io_name] = {"files": io_data, "type" :  FilesStorage.InputSourceFileType.image.name}
        FilesStorage.__validate__(return_json_data)
        return return_json_data

    def parse_inputs(self, console_input_files_list_per_model: str):
        if if_file(console_input_files_list_per_model):
            with open(console_input_files_list_per_model) as file:
                json_input = json.load(file)
        else:
            try:
                json_input = json.loads(console_input_files_list_per_model)
            except json.JSONDecodeError as ex:
                raise RuntimeError(f"Cannot parse JSON input: {repr(console_input_files_list_per_model)[1:-1]}. Error: {ex}") from None

        self.files_per_input_json = FilesStorage.__parse_json_obj__(json_input)

    def inputs(self):
        return self.files_per_input_json

class UseCaseFiles:
    use_case_separator = ";"

    def __init__(self, console_input_files_list):
        self.files_per_case = UseCaseFiles.parse_inputs(console_input_files_list)

    @staticmethod
    def parse_inputs(console_input_files_list: str):
        if console_input_files_list is None:
            return

        files_per_case = []
        file_paths_per_case = console_input_files_list.split(
            UseCaseFiles.use_case_separator
        )
        for case_files in file_paths_per_case:
            files_aggregator = FilesStorage()
            files_aggregator.parse_inputs(case_files)
            files_per_case.append(files_aggregator)
        return files_per_case


