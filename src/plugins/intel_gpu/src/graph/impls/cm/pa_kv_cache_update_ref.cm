/*******************************************************************************
 * Copyright (c) 2022-2025 Intel Corporation
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *******************************************************************************/

#include <cm/cm.h>
#include <cm/cmtl.h>

#ifndef ATTR
#define ATTR [[type("svmptr_t")]]
#define ATTR_BUF [[type("buffer_t")]]
#endif

constexpr uint wg_size = WG_SIZE;
#define REG_K 16

extern "C" _GENX_MAIN_ void KERNEL_NAME(
    const half* key [[type("svmptr_t")]],
    const half* value [[type("svmptr_t")]],
    const int32_t* past_lens [[type("svmptr_t")]],
    const int32_t* block_indices [[type("svmptr_t")]],
    const int32_t* block_indices_begins [[type("svmptr_t")]],
    const int32_t* subsequence_begins [[type("svmptr_t")]],
#if KV_CACHE_COMPRESSION_PER_TOKEN
    uint8_t* key_cache [[type("svmptr_t")]],
    uint8_t* value_cache [[type("svmptr_t")]],
#else
    half* key_cache [[type("svmptr_t")]],
    half* value_cache [[type("svmptr_t")]],
#endif   
    uint32_t key_pitch,
    uint32_t key_offset,
    uint32_t value_pitch,
    uint32_t value_offset,
    uint32_t batch_size_in_sequences) {
    // # key:   [batch_size_in_tokens, num_kv_heads * k_head_size]
    // # value  [batch_size_in_tokens, num_kv_heads * v_head_size]
    // # key_cache:   [num_blocks, num_heads, block_size, k_head_size]
    // # value_cache: [num_blocks, num_heads, block_size, v_head_size]
    // 
    // # past_lens: [sequences_num]
    // # subsequence_begins: [sequences_num + 1]
    // # block_indices: [used_blocks_num]
    // # block_indices_begins: [sequences_num + 1]

    // wg_count = aligned_to(batch_size_in_tokens, wg_size) // wg_size
    // # GWS [1, num_heads, wg_count * wg_size]
    // # LWS [1, 1, wg_size]

    const auto head_idx = cm_group_id(1);
    const auto wg_id = cm_group_id(2);
    const auto wg_local_id = cm_local_id(2);
    const auto local_size = cm_local_size(2);

    const uint token_idx = cm_global_id(2);

    // token_idx -> subsequence_idx
    if (token_idx >= subsequence_begins[batch_size_in_sequences]) return;
    uint subsequence_idx = 0;
    for (uint i = 0; i < batch_size_in_sequences; i++) {
        if (token_idx >= subsequence_begins[i] && token_idx < subsequence_begins[i + 1]) {
            subsequence_idx = i;
            break;
        }
    }

    const uint subsequence_begin_idx = subsequence_begins[subsequence_idx];
    const uint past_len = past_lens[subsequence_idx];
    const uint current_block_idx = (past_len + token_idx - subsequence_begin_idx) / PAGED_ATTENTION_BLOCK_SIZE;
    const uint token_start_pos = (past_len + token_idx - subsequence_begin_idx) % PAGED_ATTENTION_BLOCK_SIZE;
    const uint block_offset = block_indices_begins[subsequence_idx] + current_block_idx;

    #if KV_CACHE_COMPRESSION_PER_TOKEN
    // Assume: K_HEAD_SIZE == K_HEAD_SIZE
    auto quantize_and_store = [&](vector<half, K_HEAD_SIZE> data, uchar* out, uint out_offset, uint token_pos) {
            uint scale_offset = out_offset + K_HEAD_SIZE * PAGED_ATTENTION_BLOCK_SIZE + token_pos * sizeof(half);
            half max_val = cm_reduced_max<half>(data);
            half min_val = cm_reduced_min<half>(data);
            half scale_val = half(0.0);
            half zp_val = half(0.0);
            if(max_val == min_val) {
                scale_val = half(0.0);
                zp_val = max_val;
            } else {
                scale_val = 255.0 / (max_val - min_val);
                zp_val = (0.0 - min_val) * scale_val;
            }
            vector<half, K_HEAD_SIZE>  dequant_data = cm_mul<half>(data, scale_val) + zp_val;
            vector<uchar, K_HEAD_SIZE> data_u8 = cm_rnde<uchar, K_HEAD_SIZE>(dequant_data);
            cm_ptr_store<uint32_t, K_HEAD_SIZE / 4>((uint32_t*)(out + out_offset + token_pos * K_HEAD_SIZE), 0, data_u8.format<uint32_t>());
            half *out_scale_zp = (half*)(out + scale_offset);
            out_scale_zp[0] = (max_val - min_val) / 255.0;
            out_scale_zp[PAGED_ATTENTION_BLOCK_SIZE] = zp_val;
    };
    #endif

    {
        uint block_k_base_offset = (block_indices[block_offset] * KV_HEADS_NUM + head_idx) * ADJUSTED_K_HEAD_SIZE * PAGED_ATTENTION_BLOCK_SIZE;
        uint key_out_offset = block_k_base_offset + token_start_pos * K_HEAD_SIZE;
        uint key_in_offset = token_idx * key_pitch + head_idx * K_HEAD_SIZE + key_offset;

        vector<half, K_HEAD_SIZE> key_data;
        key_data.format<int>() = cm_ptr_load<int, K_HEAD_SIZE / 2>((int*)key, key_in_offset * (int)sizeof(half));

        #if KV_CACHE_COMPRESSION_PER_TOKEN
        quantize_and_store(key_data, (uchar*)key_cache, block_k_base_offset, token_start_pos);
        #else
        cm_ptr_store<int, K_HEAD_SIZE / 2>((int*)key_cache, key_out_offset * (int)sizeof(half), key_data.format<int>());
        #endif
    }
    {
        uint block_v_base_offset = (block_indices[block_offset] * KV_HEADS_NUM + head_idx) * ADJUSTED_V_HEAD_SIZE * PAGED_ATTENTION_BLOCK_SIZE;
        uint value_out_offset = block_v_base_offset + token_start_pos * V_HEAD_SIZE;
        uint value_in_offset = token_idx * value_pitch + head_idx * V_HEAD_SIZE + value_offset;

        vector<half, V_HEAD_SIZE> value_data;
        value_data.format<int>() = cm_ptr_load<int, V_HEAD_SIZE / 2>((int*)value, value_in_offset * (int)sizeof(half));
        #if KV_CACHE_COMPRESSION_PER_TOKEN
        quantize_and_store(value_data, (uchar*)value_cache, block_v_base_offset, token_start_pos);
        #else
        cm_ptr_store<int, V_HEAD_SIZE / 2>((int*)value_cache, value_out_offset * (int)sizeof(half), value_data.format<int>());
        #endif
    }
}
