/*******************************************************************************
 * Copyright (c) 2022-2025 Intel Corporation
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *******************************************************************************/
namespace KERNEL_NAME {

#include <cm/cm.h>
#include "cm/cmtl.h"
#define FP32_MIN (-1e+38)
#define FP16_MIN ((fp16)-65504.0f)

using fp16 = half;
constexpr uint32_t baseOffsetInc8[8] = { 0, 1, 2, 3, 4, 5, 6, 7 };
constexpr uint32_t baseOffsetInc16[16] = { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15 };
#define XMX_PRECISION CM_PRECISION_HF

// Shape Q [num_head, activation token length, 80]  fp16,
// Shape K:  [num_head, kv len, 80] Bf16,
// Shape V : [num_head, kv len, 80] Bf16,
// output: [activation token length, 16, 80]  Bf,
// atten = mat_mul(q, k), shape = [first token length, kv len]
// atten = softmax(atten)
// output = mat_mul(atten, V)
_GENX_MAIN_ void KERNEL_NAME(
  uint8_t* qState [[type("svmptr_t")]],
  uint8_t* kState [[type("svmptr_t")]],
  uint8_t* vState [[type("svmptr_t")]],
  uint8_t* batchInfo [[type("svmptr_t")]],
  uint8_t* out [[type("svmptr_t")]],
  uint32_t batchSize,
  uint32_t hasMask) {
  constexpr float matMulQuantCoeff = 0.1118033988749895f;
  constexpr uint32_t headChannel = 80;
  constexpr uint32_t numberOfHead = 16;
  constexpr uint32_t hiddenDim = headChannel * numberOfHead;
  constexpr uint32_t slmSize = 32 * headChannel * 4 * sizeof(fp16) + 512 * sizeof(float) + 512 * sizeof(float);
  constexpr uint32_t startActivationIdx = 0;
  cm_slm_init(slmSize);
  uint32_t slmX = cm_slm_alloc(slmSize);
  constexpr uint32_t slmOffsetBase0 = 0;
  constexpr uint32_t slmOffsetBase1 = 32 * 2 * headChannel * sizeof(fp16);
  constexpr uint32_t slmOffsetBase2 = 4 * 32 * headChannel * sizeof(fp16);
  constexpr uint32_t slmOffsetBase3 = slmOffsetBase2 + 512 * sizeof(float);
  int32_t sub_group_id = cm_local_id(0);
  int32_t _hh_ = sub_group_id & 0x1f;
  int32_t _vv_ = sub_group_id >> 5;
  int32_t _hh__ = sub_group_id & 0x1;
  int32_t _vv__ = sub_group_id >> 1;
  int32_t _bits_0_1 = _vv__ & 0x3;
  int32_t _bits_2_ = (_vv__ & 0x4) >> 2;
  int32_t _bits_3_4 = (_vv__ & 0x18) >> 1;
  _bits_3_4 = _bits_3_4 | _bits_0_1;
  int32_t h = cm_group_id(0);
  int32_t macro_group_id = cm_group_id(1);
  int32_t v = macro_group_id & 0x7;
  int32_t _b_ = macro_group_id >> 3;
  int32_t _head_ = v * 2;
  int32_t _loop_count_;
  uint32_t _bs_;
  uint32_t _kv_seq_;
  vector<fp16, 8 * 80> fp16Temp0 = 0;
  vector<fp16, 16 * 32> fp16Temp1;
  auto fp16Temp2 = fp16Temp1.format<fp16>().select<512, 1>(0);
  vector<fp16, 80> fp16Temp3;
  vector<fp16, 8 * 80> fp16Temp4 = 0;
  vector<uint32_t, 32> offsets;
  vector<uint32_t, 8> offsets_base(baseOffsetInc8);
  vector<uint32_t, 2> seqDim;
  offsets.select<8, 1>(0) = offsets_base + 2 * _b_;
  offsets.select<8, 1>(0) = offsets.select<8, 1>(0) * sizeof(uint32_t);
  seqDim =
    cm_ptr_load<
    uint32_t,
    VectorSize::N1,
    DataSize::U32,
    CacheHint::Cached,
    CacheHint::Cached,
    2
    >((uint32_t*)batchInfo, offsets.select<2, 1>(0));
  _kv_seq_ = seqDim[1];
  _bs_ = seqDim[0];

  uint32_t offsetBase0 = _bs_ * hiddenDim * sizeof(fp16) + (_head_ + _vv_) * headChannel * sizeof(fp16);
  uint32_t offsetBase1 = (_bs_ * hiddenDim + (_head_ + _hh__) * headChannel + _vv__ * hiddenDim) * sizeof(fp16);
  uint32_t offsetBase2 = (_bs_ * hiddenDim + (_head_ + _hh__) * headChannel + (_kv_seq_ - 1) * hiddenDim) * sizeof(fp16);
  uint32_t offsetBase3 = slmOffsetBase0 + _hh__ * 32 * headChannel * sizeof(fp16) + _bits_3_4 * 32 + _bits_2_ * 16 * 32;
  uint32_t offsetBase4 = slmOffsetBase0 + _vv_ * 32 * headChannel * sizeof(fp16) + (sub_group_id & 0x1) * 512;
  uint32_t offsetBase5 = slmOffsetBase1 + _hh__ * 32 * headChannel * sizeof(fp16) + _vv__ * 160;
  uint32_t offsetBase6 = slmOffsetBase1 + _vv_ * 32 * headChannel * sizeof(fp16);

  if (256 * h >= _kv_seq_) {
    return;
  }

  offsets.select<8, 1>(0) = offsets_base + h * 256 + _hh_ * 8;
  offsets.select<8, 1>(0) = cm_min<uint32_t>(offsets.select<8, 1>(0), _kv_seq_ - 1);
  offsets.select<8, 1>(0) = offsets.select<8, 1>(0) * hiddenDim * sizeof(fp16) + offsetBase0; // todo

#pragma unroll
  for (int k = 0; k < 5; k++) {
    fp16Temp0.format<uint32_t>().select<64, 1>(64 * k) =
      cm_ptr_load<
      uint32_t,
      VectorSize::N8,
      DataSize::U32,
      CacheHint::Cached,
      CacheHint::Cached,
      8
      >((uint32_t*)qState, offsets.select<8, 1>(0));
    offsets.select<8, 1>(0) += 32;
  }

  vector<float, 8> slmTemp = 0; 
  cm_store_slm<float, 8>(slmOffsetBase2 + sub_group_id * 32, slmTemp.select<8, 1>(0));
  slmTemp = FP32_MIN * matMulQuantCoeff;
  cm_store_slm<float, 8>(slmOffsetBase3 + sub_group_id * 32, slmTemp);
  _loop_count_ = (_kv_seq_ + 0x1f) >> 5;
  offsets.select<8, 1>(0) = offsets_base;
  offsets.select<8, 1>(8) = offsets.select<8, 1>(0) + 8;
  offsets.select<16, 1>(16) = offsets.select<16, 1>(0) + 16;
  for (int loopIdx = 0; loopIdx < _loop_count_; loopIdx++) {
    offsetBase1 = cm_min<uint32_t>(offsetBase2, offsetBase1);
    fp16Temp2.format<uint32_t>().select<32, 1>(0) =
      cm_ptr_load<
      uint32_t,
      32,
      DataSize::U32,
      CacheHint::Cached,
      CacheHint::Cached,
      CacheHint::Default
      >((uint32_t*)kState, offsetBase1);
    fp16Temp2.format<uint32_t>().select<8, 1>(32) =
      cm_ptr_load<
      uint32_t,
      8,
      DataSize::U32,
      CacheHint::Cached,
      CacheHint::Cached,
      CacheHint::Default
      >((uint32_t*)kState, offsetBase1 + 128);

    fp16Temp3.format<uint32_t>().select<32, 1>(0) =
      cm_ptr_load<
      uint32_t,
      32,
      DataSize::U32,
      CacheHint::Cached,
      CacheHint::Cached,
      CacheHint::Default
      >((uint32_t*)vState, offsetBase1);
    fp16Temp3.format<uint32_t>().select<8, 1>(32) =
      cm_ptr_load<
      uint32_t,
      8,
      DataSize::U32,
      CacheHint::Cached,
      CacheHint::Cached,
      CacheHint::Default
      >((uint32_t*)vState, offsetBase1 + 128);
#pragma unroll
    for (int k = 0; k < 5; k++) {
      cm_store_slm<fp16, 16>(offsetBase3 + k * 1024, fp16Temp2.select<16, 1>(16 * k));
    }
    vector<float, 8 * 32> tempOutput;
    vector<float, 8> fp32Temp0;
    vector<float, 8> fp32Temp1;
    vector<float, 8> fp32Temp2;
    vector<float, 16> fp32Temp3;
    vector<float, 16> fp32Temp4;
    cm_slm_fence(0x20);
    cm_barrier();
  
#pragma unroll
    for (int kk = 0; kk < 2; kk++) {
      fp16Temp2.select<128, 1>(128 * kk) = cm_load_slm<fp16, 128>(offsetBase4 + kk * 256);
    }

#pragma unroll
    for (int kk = 0; kk < 4; kk++) {
      tempOutput.select<64, 1>(64 * kk) =
        cm_dpasw<CM_PRECISION_HF, CM_PRECISION_HF, 8, 8, float, uint32_t, uint32_t, 64, 64, 32>(
          0,
          fp16Temp0.format<uint32_t>().select<64, 1>(0),
          fp16Temp2.format<uint32_t>().select<32, 1>(32 * kk));
    }

#pragma unroll
    for (int k = 1; k < 5; k++) {
#pragma unroll
      for (int kk = 0; kk < 2; kk++) {
        fp16Temp2.select<128, 1>(128 * kk) = cm_load_slm<fp16, 128>(offsetBase4 + k * 1024 + kk * 256);
      }

#pragma unroll
      for (int kkk = 0; kkk < 4; kkk++) {
        tempOutput.select<64, 1>(64 * kkk) =
          cm_dpasw<CM_PRECISION_HF, CM_PRECISION_HF, 8, 8>(
            tempOutput.select<64, 1>(64 * kkk),
            fp16Temp0.format<uint32_t>().select<64, 1>(64 * k),
            fp16Temp2.format<uint32_t>().select<32, 1>(32 * kkk));
      }
    }

    fp32Temp2.select<8, 1>(0) = cm_load_slm<float, 8>(slmOffsetBase2 + sub_group_id * 32);
    fp32Temp0.select<8, 1>(0) = cm_load_slm<float, 8>(slmOffsetBase3 + sub_group_id * 32);
#pragma unroll
    for (int kk = 0; kk < 32; kk++) {
      tempOutput.select<8, 1>(8 * kk).merge(FP32_MIN, offsets.replicate<8, 1>(kk) >= _kv_seq_);
    }
    tempOutput = tempOutput * matMulQuantCoeff;

    fp32Temp3.select<8, 1>(0) = fp32Temp0;
    fp32Temp3.select<8, 1>(8) = fp32Temp3.select<8, 1>(0);
#pragma unroll
    for (int32_t kk = 0; kk < 16; kk++) {
      fp32Temp3.select<16, 1>(0) = cm_max<float>(tempOutput.select<16, 1>(16 * kk), fp32Temp3.select<16, 1>(0));
    }

    fp32Temp3.select<8, 1>(0) = cm_max<float>(fp32Temp3.select<8, 1>(0), fp32Temp3.select<8, 1>(8));
    fp32Temp3.select<8, 1>(8) = fp32Temp3.select<8, 1>(0);
#pragma unroll
    for (int kk = 0; kk < 16; kk++) {
      tempOutput.select<16, 1>(16 * kk) = tempOutput.select<16, 1>(16 * kk) - fp32Temp3.select<16, 1>(0);
      tempOutput.select<16, 1>(16 * kk) = cm_pow(2.718281828459f, tempOutput.select<16, 1>(16 * kk));
    }

    fp32Temp1 = fp32Temp0 - fp32Temp3.select<8, 1>(0);
    fp32Temp1 = cm_pow(2.718281828459f, fp32Temp1);

    if (loopIdx != 0) {
      fp32Temp2.select<8, 1>(0) = fp32Temp2.select<8, 1>(0) * fp32Temp1.select<8, 1>(0);
#pragma unroll
      for (int32_t kk = 0; kk < 8; kk++) {
        fp16Temp4.select<80, 1>(80 * kk) = fp16Temp4.select<80, 1>(80 * kk) * fp32Temp1[kk];
      }
    }

    fp32Temp4 = tempOutput.select<16, 1>(0);
#pragma unroll
    for (int32_t kk = 1; kk < 16; kk++) {
      fp32Temp4.select<16, 1>(0) = fp32Temp4.select<16, 1>(0) + tempOutput.select<16, 1>(16 * kk);
    }
    fp32Temp4.select<8, 1>(0) += fp32Temp4.select<8, 1>(8);
    fp32Temp2 += fp32Temp4.select<8, 1>(0);

    cm_store_slm<float, 8>(slmOffsetBase2 + sub_group_id * 32, fp32Temp2.select<8, 1>(0));
    cm_store_slm<float, 8>(slmOffsetBase3 + sub_group_id * 32, fp32Temp3.select<8, 1>(0));

    cm_store_slm<fp16, 64>(offsetBase5, fp16Temp3.select<64, 1>(0));
    cm_store_slm<fp16, 16>(offsetBase5 + 128, fp16Temp3.select<16, 1>(64));
    fp16Temp1.select<256, 1>(0) = tempOutput;

    cm_slm_fence(0x20);
    cm_barrier();

    vector<fp16, 640> tempOutputAsFp16;
#pragma unroll
    for (int32_t k = 0; k < 4; k++) {
#pragma unroll
      for (int32_t kk = 0; kk < 5; kk++) {
        tempOutputAsFp16.select<128, 1>(128 * kk) = cm_load_slm<fp16, 128>(offsetBase6 + 1280 * k + kk * 256);
      }

#pragma unroll
      for (int32_t kk = 0; kk < 8; kk++) {
#pragma unroll
        for (int32_t kkk = 0; kkk < 8; kkk++) {
          fp16Temp4.select<16, 1>(kkk * 80) += tempOutputAsFp16.select<16, 1>(80 * kk) * fp16Temp1[64 * k + kkk + 8 * kk];
          fp16Temp4.select<16, 1>(kkk * 80 + 16 * 1) += tempOutputAsFp16.select<16, 1>(80 * kk + 16 * 1) * fp16Temp1[64 * k + kkk + 8 * kk];
          fp16Temp4.select<16, 1>(kkk * 80 + 16 * 2) += tempOutputAsFp16.select<16, 1>(80 * kk + 16 * 2) * fp16Temp1[64 * k + kkk + 8 * kk];
          fp16Temp4.select<16, 1>(kkk * 80 + 16 * 3) += tempOutputAsFp16.select<16, 1>(80 * kk + 16 * 3) * fp16Temp1[64 * k + kkk + 8 * kk];
          fp16Temp4.select<16, 1>(kkk * 80 + 16 * 4) += tempOutputAsFp16.select<16, 1>(80 * kk + 16 * 4) * fp16Temp1[64 * k + kkk + 8 * kk];
        }
      }
    }

    offsetBase1 += hiddenDim * 64;
    offsets += 32;
    cm_slm_fence(0x20);
    cm_barrier();
  }

  vector<float, 8> _dividor_;
  _dividor_.select<8, 1>(0) = cm_load_slm<float, 8>(slmOffsetBase2 + 32 * sub_group_id);
  _dividor_ = 1.0f / _dividor_;

#pragma unroll
  for (int32_t kk = 0; kk < 8; kk++) {
    fp16Temp4.select<80, 1>(80 * kk) = fp16Temp4.select<80, 1>(80 * kk) * _dividor_[kk];
  }

  uint32_t startOutputId = h * 256 + _hh_ * 8;
  uint32_t startOutputBase;
  uint32_t outputStride;
//  if (hasMask == 1) {
    startOutputBase = _bs_ * hiddenDim * sizeof(fp16) + (_head_ + _vv_) * headChannel * sizeof(fp16) + startOutputId * hiddenDim * sizeof(fp16);
    outputStride = hiddenDim * sizeof(fp16);
//  } else {
//    startOutputBase = _bs_ * hiddenDim * sizeof(fp16) + (_head_ + _vv_) * headChannel * _kv_seq_ * sizeof(fp16) + startOutputId * headChannel * sizeof(fp16);
//    outputStride = headChannel * sizeof(fp16);
//  }
#pragma unroll
  for (int32_t kk = 0; kk < 8; kk++) {
    if (startOutputId + kk < _kv_seq_) {
      cm_ptr_store<
        uint32_t,
        32,
        DataSize::U32,
        CacheHint::WriteBack,
        CacheHint::WriteBack,
        CacheHint::Default
      >((uint32_t*)out, startOutputBase, fp16Temp4.format<uint32_t>().select<32, 1>(40 * kk));

      cm_ptr_store<
        uint32_t,
        8,
        DataSize::U32,
        CacheHint::WriteBack,
        CacheHint::WriteBack,
        CacheHint::Default
      >((uint32_t*)out, startOutputBase + 32 * sizeof(uint32_t), fp16Temp4.format<uint32_t>().select<8, 1>(40 * kk + 32));
      startOutputBase += outputStride;
    }
  }
}
}  // NAMESPACE