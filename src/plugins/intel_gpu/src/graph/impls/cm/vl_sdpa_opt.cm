/*******************************************************************************
 * Copyright (c) 2022-2025 Intel Corporation
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *******************************************************************************/

namespace KERNEL_NAME {

#include "include/vl_sdpa.h"

// #pyeval f"#define num_heads {num_heads}"
// #pyeval f"#define num_kv_heads {num_kv_heads}"
// #pyeval f"#define head_size {head_size}"
// #pyeval f"#define q_step {q_step}"
// #pyeval f"#define kv_step {kv_step}"
// #pyeval f"#define scale_factor {scale_factor}"
// #pyeval f"#define args_verbose {args.verbose}"
// #pyeval f"#define WG_SIZE {WG_SIZE}"

#define SystolicDepth 8
#define RepeatCount 8
#define VNNI_WIDTH 2
#define REG_K (SystolicDepth * VNNI_WIDTH)
#define REG_M RepeatCount
#define REG_N 16

static_assert(q_step == 16);
static_assert(kv_step == 16);

_GENX_MAIN_ void KERNEL_NAME(
    half* query [[type("svmptr_t")]],
    half* key [[type("svmptr_t")]],
    half* value [[type("svmptr_t")]],
#if HAS_ATTN_MASK_INPUT
    half* mask [[type("svmptr_t")]],
#endif
    half* output [[type("svmptr_t")]],
    int valid_q_len,
    int valid_kv_len,
    int q_len,   int kv_len,
    int start_q_pos, int start_kv_pos
    ) {
    //# query [batch, q_len, num_heads, S]
    //#   key [batch, kv_len, num_heads, S]
    //# value [batch, kv_len, num_heads, S]
    //# to load Q

    constexpr uint K_SLM_SIZE = (kv_step * head_size * sizeof(half));
    constexpr uint V_SLM_SIZE = (kv_step * head_size * sizeof(half));
    constexpr uint Q_SLM_SIZE = 0;//(q_step * head_size * sizeof(half)) * WG_SIZE;

    cm_slm_init(K_SLM_SIZE + V_SLM_SIZE + Q_SLM_SIZE);

    auto slm_K = cm_slm_alloc(K_SLM_SIZE);
    auto slm_V = cm_slm_alloc(V_SLM_SIZE);

    vector<float, q_step> cur_max;
    vector<float, q_step> cur_sum;

    cur_max = -1e9;
    cur_sum = 0;
    
    auto WG_SIZE = cm_local_size(2);
    //# printf("WG_SIZE = ", WG_SIZE);

    auto batch = cm_global_id(0);
    auto h = cm_global_id(1);
    auto hkv = h / (num_heads/num_kv_heads);
    auto wg_local_id = cm_local_id(2);
    auto q_start = cm_global_id(2) * q_step;
    auto q_offset = wg_local_id * q_step * head_size * sizeof(half);
    auto o_offset = wg_local_id * q_step * head_size * sizeof(float);

    //# debugging stage
#if HAS_ATTN_MASK_INPUT
    lsc::block_2d_desc<half, 1, REG_M, REG_N> b2dMask(mask + batch * q_len * kv_len, q_len - 1, kv_len*sizeof(half) - 1, kv_len*sizeof(half) - 1, 0, 0);
#endif

    //# b2dQ reinterpret as 32bit(DWORD) for transposed load(combined with VNNI)
    uint qo_pitch = num_heads * head_size * sizeof(half);
    uint kv_pitch = num_kv_heads * head_size * sizeof(half);
    lsc::block_2d_desc<uint, 1, REG_N, REG_K/2> b2dQ(reinterpret_cast<uint*>(query + (batch*num_heads*q_len + h)*head_size), q_len - 1, head_size*sizeof(half) - 1, qo_pitch - 1, 0, 0);
    lsc::block_2d_desc<half, 1, REG_M, REG_K> b2dK(key + (batch*num_kv_heads*kv_len + hkv)*head_size,   kv_len - 1, head_size*sizeof(half) - 1, kv_pitch - 1, 0, 0);
    lsc::block_2d_desc<half, 1, REG_K, REG_N> b2dV(value + (batch*num_kv_heads*kv_len + hkv)*head_size, kv_len - 1, head_size*sizeof(half) - 1, kv_pitch - 1, 0, 0);
    lsc::block_2d_desc<half, 1, REG_M, REG_N> b2dO(output + (batch*num_heads*q_len + h)*head_size,   q_len - 1, head_size*sizeof(half) - 1, qo_pitch - 1, 0, 0);

    //# load Qt into register & pack as VNNI & store to SLM (as dpas-B tile)

    matrix<half, head_size/REG_K, REG_K*REG_N> rQ;
    {
        //matrix<uint, REG_K/2, REG_N> Qmat;
        #pragma unroll
        for(int k = 0, ri = 0; k < head_size/2; k += REG_K/2, ri++) {
            b2dQ.set_block_x(k);

            //# DWORD transposed load == (transposed + VNNI) load
            cm_load<lsc::Transpose>(rQ[ri].format<uint>(), b2dQ.set_block_y(q_start+start_q_pos));

            //show(Qmat.format<half, REG_K/2, REG_N*2>());
        }
    }

    int kv_stop = valid_kv_len + start_kv_pos;

    matrix <float, head_size/REG_K*2, REG_M*REG_N> rO;
    for(int kv_pos = start_kv_pos; kv_pos < kv_stop; kv_pos += kv_step) {
        // if (args_verbose >= 0) printf("======== %d =========\n", kv_pos);

        //===========================================================
        //# load K into SLM as dpas-A tile (shared by all hw within same WG)
        //# load V into SLM as dpas-B tile (shared by all hw within same WG)
        {
            //# 1849 ~ 3259
            if (kv_pos > start_kv_pos) cm_barrier();
            {
                // auto clk0 = get_clock();
                if (WG_SIZE == 1) {
                    matrix<half, REG_M, REG_K> temp0;
                    matrix<half, REG_M, REG_K> temp1;
                    for(int k = 0; k < head_size; k += REG_K) {
                        b2dK.set_block_x(k);
                        cm_load<lsc::Normal>(temp0.format<half>(), b2dK.set_block_y(kv_pos));
                        cm_load<lsc::Normal>(temp1.format<half>(), b2dK.set_block_y(kv_pos + REG_M));

                        //cm_prefetch(b2dK.set_block_y(kv_pos + kv_step));
                        //cm_prefetch(b2dK.set_block_y(kv_pos + kv_step + REG_M));

                        //show(temp0); return;
                        
                        uint offset = k * 2 * REG_M * sizeof(half);
                        cm_slm_block_write(slm_K, offset, temp0.format<half>());
                        offset += REG_M * REG_K * sizeof(half);
                        cm_slm_block_write(slm_K, offset, temp1.format<half>());
                    }
                    matrix<half, REG_K, REG_N> temp2;
                    b2dV.set_block_y(kv_pos);
                    for(int k = 0; k < head_size; k += REG_K) {
                        cm_load<lsc::VNNI>(temp2.format<half>(), b2dV.set_block_x(k).set_block_y(kv_pos));
                        //cm_prefetch(b2dV.set_block_y(kv_pos + kv_step));

                        cm_slm_block_write(slm_V, k * REG_N * sizeof(half), temp2.format<half>());
                    }
                } else {
                    if (wg_local_id < WG_SIZE/2) {
                        matrix<half, REG_M, REG_K> temp0;
                        matrix<half, REG_M, REG_K> temp1;
                        for(int k = REG_K*wg_local_id; k < head_size; k += REG_K*(WG_SIZE/2)) {
                            b2dK.set_block_x(k);
                            cm_load<lsc::Normal>(temp0.format<half>(), b2dK.set_block_y(kv_pos));
                            cm_load<lsc::Normal>(temp1.format<half>(), b2dK.set_block_y(kv_pos + REG_M));

                            //cm_prefetch(b2dK.set_block_y(kv_pos + kv_step));
                            //cm_prefetch(b2dK.set_block_y(kv_pos + kv_step + REG_M));

                            uint offset = k * 2 * REG_M * sizeof(half);
                            cm_slm_block_write(slm_K, offset, temp0.format<half>());
                            offset += REG_M * REG_K * sizeof(half);
                            cm_slm_block_write(slm_K, offset, temp1.format<half>());
                        }
                    } else {
                        matrix<half, REG_K, REG_N> temp2;
                        b2dV.set_block_y(kv_pos);
                        for(int k = REG_K*(wg_local_id-WG_SIZE/2); k < head_size; k += REG_K*(WG_SIZE/2)) {
                            cm_load<lsc::VNNI>(temp2.format<half>(), b2dV.set_block_x(k).set_block_y(kv_pos));
                            //cm_prefetch(b2dV.set_block_y(kv_pos + kv_step));

                            cm_slm_block_write(slm_V, k * REG_N * sizeof(half), temp2.format<half>());
                        }
                    }
                }
            }
            // printf(" diff= %lu\n", get_clock() - clk0);

            cm_barrier();
        }

        //=========================================================== 1807 ~ 3247
        //# St = k @ Qt
        matrix<float, 2*REG_M, REG_N> St = 0;
        matrix<half, 2, REG_M * REG_K> Kmat;
        matrix<half, REG_K/2, REG_N*2> Qmat;
        auto St2 = St.format<float, 2, REG_M*REG_N>();
        uint offset = 0;
        #pragma unroll
        for(int k = 0, ri = 0; k < head_size; k += REG_K, ri++) {
            cm_slm_block_read(slm_K, GENX_NONE, offset, Kmat[0]); offset += REG_M * REG_K * sizeof(half);
            cm_slm_block_read(slm_K, GENX_NONE, offset, Kmat[1]); offset += REG_M * REG_K * sizeof(half);
            //show(Kmat.format<half, 2*REG_M, REG_K>());

            St2[0] = cm_dpas<CM_PRECISION_HF, CM_PRECISION_HF, SystolicDepth, RepeatCount>(
                        St2[0],
                        rQ[ri].format<int32_t>(),
                        Kmat[0].format<int32_t>());
            St2[1] = cm_dpas<CM_PRECISION_HF, CM_PRECISION_HF, SystolicDepth, RepeatCount>(
                        St2[1],
                        rQ[ri].format<int32_t>(),
                        Kmat[1].format<int32_t>());
        }
        //show(St);
        //=========================================================== 361
#if HAS_ATTN_MASK_INPUT
        matrix<half, 2, REG_M * REG_N> Maskmat;
        b2dMask.set_block_x(kv_pos);
        cm_load<lsc::Normal>(Maskmat[0].format<half>(), b2dMask.set_block_y(q_start));
        cm_load<lsc::Normal>(Maskmat[1].format<half>(), b2dMask.set_block_y(q_start + REG_M));

        matrix<float, 2*REG_M, REG_N> MaskT;
        Transpose_16x16(Maskmat.format<half, 2*REG_M, REG_N>(), MaskT);

        //show(Maskmat);
#endif
        St = cm_mul<float>(St, (float)scale_factor);  // convert scale_factor into (float), or it will be promoted to double
#if HAS_ATTN_MASK_INPUT
        St = cm_add<float>(St, MaskT);
#endif

        //show(St);

        vector<float, REG_N> new_max_t;
        new_max_t = cm_max<float>(St[0], St[1]);
        for(int r = 2; r < St.n_rows(); r++) new_max_t = cm_max<float>(new_max_t, St[r]);

        //show(new_max_t.format<float, 1, REG_N>()); return;

        new_max_t = cm_max<float>(new_max_t, cur_max);

        constexpr float log2e = 1.4426950408889634f;
        // Pt = torch.exp(St - new_max)
        for(int r = 0; r < St.n_rows(); r++) St[r] = cm_exp((St[r] - new_max_t)*log2e);
        //show(St); return;

        vector<float, REG_N> row_sum_t;
        row_sum_t = cm_add<float>(St[0], St[1]);
        for(int r = 2; r < St.n_rows(); r++) row_sum_t = cm_add<float>(row_sum_t, St[r]);

        vector<float, REG_N> max_comp;
        max_comp = cm_exp((cur_max - new_max_t)*log2e);
        cur_sum = cm_mul<float>(cur_sum, max_comp);
        cur_sum = cm_add<float>(cur_sum, row_sum_t);

        matrix<half, 2*REG_M, REG_K> P;
        Transpose_16x16(St, P);

        //show(cur_sum.format<float, 1, REG_N>()); return;
        //============================================================== 1074


        //============================================================== 666
        //show(P);return;
        //auto clk0 = get_clock();

        auto P2 = P.format<half, 2, REG_M * REG_K>();
        matrix<float, 2, REG_M*REG_N> cur_O;
        if (kv_pos == 0) {
            matrix<float, REG_M, REG_N> zero_O = 0;
            matrix<half, REG_K/2, REG_N*2> Vmat;
            uint offset = o_offset;
            #pragma unroll
            for(int k = 0, ri = 0; k < head_size; k += REG_K, ri += 2) {
                // V has been VNNI-prepacked
                cm_slm_block_read(slm_V, GENX_NONE, REG_N*k*sizeof(half), Vmat.format<half>());
                
                rO[ri] = cm_dpas<CM_PRECISION_HF, CM_PRECISION_HF, SystolicDepth, RepeatCount>(
                                zero_O.format<float>(),
                                Vmat.format<int32_t>(),
                                P2[0].format<int32_t>());
                rO[ri+1] = cm_dpas<CM_PRECISION_HF, CM_PRECISION_HF, SystolicDepth, RepeatCount>(
                                zero_O.format<float>(),
                                Vmat.format<int32_t>(),
                                P2[1].format<int32_t>());
                //show(cur_O.format<float, 2*REG_M, REG_N>());
            }
        } else {
            matrix<half, REG_K/2, REG_N*2> Vmat;
            uint offset = o_offset;
            #pragma unroll
            for(int k = 0, ri=0; k < head_size; k += REG_K, ri+=2) {
                // V has been VNNI-prepacked
                cm_slm_block_read(slm_V, GENX_NONE, REG_N*k*sizeof(half), Vmat.format<half>());

                //# compensate cur_O
                //  matrix <float, head_size/REG_K*2, REG_M*REG_N> rO;
                auto cO = rO[ri].format<float, REG_M, REG_N>();
                for(int r = 0; r < REG_M; r++)
                    cO.row(r) = cm_mul<float>(cO.row(r), max_comp[r]);
                auto cO2 = rO[ri+1].format<float, REG_M, REG_N>();
                for(int r = 0; r < REG_M; r++)
                    cO2.row(r) = cm_mul<float>(cO2.row(r), max_comp[r + REG_M]);

                //# show(cur_O.format<float, 2*REG_M, REG_N>()); return;
                
                rO[ri] = cm_dpas<CM_PRECISION_HF, CM_PRECISION_HF, SystolicDepth, RepeatCount>(
                                rO[ri].format<float>(),
                                Vmat.format<int32_t>(),
                                P2[0].format<int32_t>());
                rO[ri+1] = cm_dpas<CM_PRECISION_HF, CM_PRECISION_HF, SystolicDepth, RepeatCount>(
                                rO[ri+1].format<float>(),
                                Vmat.format<int32_t>(),
                                P2[1].format<int32_t>());

                // if (kv_pos == args_verbose) show(cur_O.format<float, 2*REG_M, REG_N>());
            }
            // if (kv_pos == args_verbose) return;
        }
        //============================================================== 1168

        cur_max = new_max_t;
    }//# for(int kv_pos = 0; kv_pos < kv_len; kv_pos += kv_step) {
    
    //# save cur_O/cur_sum.transpose(0, 1)
    matrix<float, 2, REG_M*REG_N> cur_O;
    matrix<half, 2*REG_M, REG_N> cur_O_f16;
    uint offset = o_offset;
    #pragma unroll
    for(int k = 0, ri=0; k < head_size; k += REG_K, ri+=2) {
        auto cO = rO[ri].format<float, REG_M, REG_N>();
        for(int r = 0; r < cO.n_rows(); r++) {
            cur_O_f16[r] = cm_div_ieee(cO[r], cur_sum[r]);
        }
        auto cO2 = rO[ri+1].format<float, REG_M, REG_N>();
        for(int r = 0; r < cO2.n_rows(); r++) {
            cur_O_f16[r + REG_M] = cm_div_ieee(cO2[r], cur_sum[r+REG_M]);
        }

        // if (i == args_verbose) show(cur_O_f16);

        cm_store(b2dO.set_block_x(k).set_block_y(q_start+start_q_pos), cur_O_f16.format<half, 2, REG_M*REG_N>()[0]);
        cm_store(b2dO.set_block_x(k).set_block_y(q_start+start_q_pos + REG_M), cur_O_f16.format<half, 2, REG_M*REG_N>()[1]);
    }
    // if (i == args_verbose) return;
}
}