/*******************************************************************************
 * Copyright (c) 2022-2025 Intel Corporation
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *******************************************************************************/

//cm_sdpa_2nd_reduce
extern "C" _GENX_MAIN_ void KERNEL_NAME(
    float* input [[type("svmptr_t")]],
    half* output [[type("svmptr_t")]],
    float* lse [[type("svmptr_t")]],
    int kv_partition_num
    ) {
        auto batch = cm_global_id(0);
        auto head = cm_global_id(1);
        auto offset = cm_group_id(2) * REDUCE_SPLIT_SIZE;
        const int total_partition_num = (kv_partition_num * HEADS_NUM);

        // load lse
        float total_lse = 0.0;
        uint lse_offset = batch * total_partition_num + head * kv_partition_num;
        constexpr float log2e = 1.4426950408889634f;
        float* lse_vec = lse + lse_offset;
        float lse_max = lse_vec[0];
        for(int k = 1; k < kv_partition_num; k ++) {
            lse_max = cm_max<float>(lse_vec[k], lse_max);
        }

        int iter = kv_partition_num / 16;
        for(int k = 0; k < iter * 16; k += 16) {
            #pragma unroll
            for(int ki = k; ki < k + 16; ki ++) {
                float lse_value = cm_exp<float>((lse_vec[ki] - lse_max)*log2e);
                total_lse += lse_value;
            }
        }
        for(int k = iter * 16; k < kv_partition_num; k ++) {
            float lse_value = cm_exp<float>((lse_vec[k] - lse_max)*log2e);
            total_lse += lse_value;
        }

        // load input, total_partition_num = head_nums * kv_partition_num;
        matrix<half, 1, REDUCE_SPLIT_SIZE> out_mat_f32 = 0;
        matrix<half, 1, REDUCE_SPLIT_SIZE> out_mat = 0;
        matrix<float, 1, REDUCE_SPLIT_SIZE> data_mat;
        uint input_offset = batch * total_partition_num * HEAD_SIZE + head * kv_partition_num * HEAD_SIZE + offset;

        for(int k = 0; k < iter * 16; k += 16) {
            #pragma unroll
            for(int ki = k; ki < k + 16; ki ++) {
                cm_svm_block_read<float, REDUCE_SPLIT_SIZE>((svmptr_t)(input + input_offset), data_mat.format<float>());
                input_offset += HEAD_SIZE;
                float lse_value = cm_exp<float>((lse_vec[ki] - lse_max)*log2e);
                out_mat_f32 += cm_mul<half>(data_mat, (float)(lse_value/total_lse));
            }
        }
        for(int k = iter * 16; k < kv_partition_num; k ++) {
            cm_svm_block_read<float, REDUCE_SPLIT_SIZE>((svmptr_t)(input + input_offset), data_mat.format<float>());
            input_offset += HEAD_SIZE;
            float lse_value = cm_exp<float>((lse_vec[k] - lse_max)*log2e);
            out_mat_f32 += cm_mul<half>(data_mat, (float)(lse_value/total_lse));
        }
        out_mat = out_mat_f32.format<half>();

        // write output
        uint output_offset = batch * HEADS_NUM * HEAD_SIZE + head * HEAD_SIZE + offset;
        cm_svm_block_write<half, REDUCE_SPLIT_SIZE>((svmptr_t)(output + output_offset),out_mat.format<half>());
    }