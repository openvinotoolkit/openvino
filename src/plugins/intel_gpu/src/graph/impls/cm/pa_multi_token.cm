
/*******************************************************************************
 * Copyright (c) 2022-2025 Intel Corporation
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *******************************************************************************/

namespace KERNEL_NAME {
#include "cm_sdpa_common.hpp"

#ifdef CM_HAS_LSC_UNTYPED_2D
#define USE_LSC 1
#else
#define USE_LSC 0
#endif

//extern "C" _GENX_MAIN_ void pa_multi_token(
extern "C" _GENX_MAIN_ void KERNEL_NAME(
    half* query [[type("svmptr_t")]],
    half* key [[type("svmptr_t")]],
    half* value [[type("svmptr_t")]],
    int32_t* past_lens [[type("svmptr_t")]],
    int32_t* block_indices [[type("svmptr_t")]],
    int32_t* block_indices_begins [[type("svmptr_t")]],
    int32_t* subsequence_begins [[type("svmptr_t")]],
#if SPARSE_BLOCK_SIZE > 1
    bool* sparse_block_mask [[type("svmptr_t")]],
#endif
    half* output [[type("svmptr_t")]],
    int q_len) {
    constexpr int is_causal = CMFLA_IS_CAUSAL;
    constexpr int num_heads = CMFLA_NUM_HEADS;
    constexpr int head_size = CMFLA_HEAD_SIZE;
    constexpr int num_kv_heads = CMFLA_NUM_KV_HEADS;
    constexpr int pa_block_sz = CMPA_BLOCK_SZ;
    //# query [q_len, num_heads, S]
    //#   key [kv_len, num_heads, S]
    //# value [kv_len, num_heads, S]
    //# sparse_block_mask [num_heads, q_blocks, kv_blocks]

    auto batch = cm_group_id(0);
    auto h = cm_group_id(1);
    auto hkv = h / (num_heads/num_kv_heads);
    auto wg_id = cm_group_id(2); // each work-group handles a sequence
    auto wg_local_id = cm_local_id(2);
    int local_size = cm_local_size(2);
    int q_start_sg, kv_start, kv_seq_len, q_len_sg;

    // multiple work-groups are required to split a sequence,
    // need to figure out which part of query-tokens to process
    int wg_seq_len = local_size * q_step;
    int past_q_lens = past_lens[0];
    kv_start = 0;
    kv_seq_len = q_len + past_q_lens;
    q_start_sg = (wg_id * local_size + wg_local_id) * q_step;
    q_len_sg = q_step;
    if (q_start_sg + q_len_sg > q_len) {
        q_len_sg = q_len - q_start_sg;
    }

    // qkv is fused
    int kv_stop = kv_seq_len;
    if constexpr (is_causal) {
        /*
        --------------------------------
        |       |       |       |       |
        |  00   |       |       |       |
        |       |       |       |       |
         --------------------------------
        |       |       |       |       |
        |  10   |  11   |       |       |
        |       |       |       |       |
        ---------------------------------
        |       |       |       |       |
        |  20   |  21   |  22   |       |
        |       |       |       |       |
         ---------------------------------
        |       |       |       |       |
        |  30   |  31   |   32  |   33  |
        |       |       |       |       |
        ---------------------------------
        each grid can be [q_len_per_trunk, q_len_per_trunk].
        For each trunk, [q_len_per_trunk, past_q_lens] must be calculated. Such as: `20`,`21`. but for the 22,
        causal mask optimization can be applied. different wgs would has different kv stop.
        //todo:kv_stop is wg level, should we change to sg level?
    */
        kv_stop = (wg_id + 1) * wg_seq_len + past_q_lens;
        if (kv_stop > kv_seq_len) kv_stop = kv_seq_len;
    }

    // printf("wg:%d.%d  q: %d, +%d   kv: %d, +%d, %d\n", wg_id, wg_local_id, q_start_sg, q_len_sg, kv_start, kv_seq_len, kv_stop);
    // qkv fused
    // constexpr uint num_total_heads = num_heads + num_kv_heads * 2;
    // uint q_offset = (q_start*num_total_heads + h)*head_size;
    // uint k_offset = (kv_start*num_total_heads + num_heads + hkv)*head_size;
    // uint v_offset = (kv_start*num_total_heads + num_heads + num_kv_heads + hkv)*head_size;

    //Q/O[B, L, H, S]
    uint q_offset = (q_start_sg*num_heads + h)*head_size;
    uint o_offset = (q_start_sg*num_heads + h)*head_size;

    //K/V[block_num, kv_heads, block_sz, head_sz]
    uint k_offset = hkv*head_size*pa_block_sz;
    uint v_offset = hkv*head_size*pa_block_sz;

#if SPARSE_BLOCK_SIZE > 1
    //# sparse_block_mask [num_heads, q_blocks, kv_blocks]
    auto q_start_block = q_start_sg/ SPARSE_BLOCK_SIZE;
    int q_blocks = (q_len + SPARSE_BLOCK_SIZE - 1) / SPARSE_BLOCK_SIZE;
    int kv_blocks = (kv_seq_len + SPARSE_BLOCK_SIZE - 1) / SPARSE_BLOCK_SIZE;
    bool* block_mask_base = sparse_block_mask + (h * q_blocks + q_start_block)*kv_blocks;
    // printf("wg:%d.%d  q: %d, +%d   kv: %d, +%d, %d, x-attn: %d, %dx%d, %p, %p\n", wg_id, wg_local_id, q_start_sg, q_len_sg, kv_start, kv_seq_len, kv_stop, q_start_block, q_blocks, kv_blocks, sparse_block_mask, block_mask_base);
#endif

#if USE_LSC == 1
    pa_kernel_lsc_prefetch<is_causal, num_heads, num_kv_heads, head_size, 0, 16>(
                                wg_local_id,
                                q_start_sg, //q_start for SG,
                                kv_stop,
                                q_len_sg, //q_step,
                                kv_seq_len, //kv_len, not used for now
                                reinterpret_cast<svmptr_t>(query + q_offset),
                                reinterpret_cast<svmptr_t>(key + k_offset),
                                reinterpret_cast<svmptr_t>(value + v_offset),
#if SPARSE_BLOCK_SIZE > 1
                                reinterpret_cast<svmptr_t>(block_mask_base),
#endif
                                reinterpret_cast<svmptr_t>(output + o_offset),
                                past_q_lens,
                                block_indices);
#else
    static_assert(0);

#endif
}

}  // NAMESPACE