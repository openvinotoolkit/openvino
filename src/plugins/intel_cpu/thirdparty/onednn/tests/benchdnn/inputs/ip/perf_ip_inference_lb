# inference_lb -- inference with large batch size
# f32
--reset
--dir=FWD_B
--mb=64 --batch=shapes_gnmt
--mb=512 --batch=shapes_wd
--mb=1024 --batch=shapes_wd
--mb=112 --batch=shapes_resnet_50
--mb=64 --batch=shapes_resnet_50_sparse
--mb=128 --batch=shapes_googlenet_v1
--mb=224 --batch=shapes_googlenet_v3
--mb=64 --batch=shapes_vgg16
--mb=2048 --batch=shapes_ncf
--mb=1024 --batch=shapes_alexnet
--mb=1000 --batch=shapes_maskrcnn
--mb=128 --batch=shapes_bert
--mb=128 --batch=shapes_bert_large
# mb = 16 * num_cores for rnn-t
--mb=896 --batch=shapes_rnn_t
--mb=2048 --batch=shapes_dlrm
# TR-LT has 2 parts with different mb values dependign on num cores
# please correct mb values in input list according ot description
--mb=0 --batch=shapes_transformer_lt
