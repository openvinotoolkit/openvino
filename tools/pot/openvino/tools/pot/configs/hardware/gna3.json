{
    "target_device": "GNA3",
    "input_priority_types": ["Convolution"],
    "config": {
        "quantization": {
            "q32_a": {
                "bits": 32,
                "mode": "symmetric",
                "granularity": "pertensor",
                "level_low": -2147483648,
                "level_high": 2147483647
            },
            "q16_a": {
                "bits": 16,
                "mode": "symmetric",
                "granularity": "pertensor",
                "level_low": -32768,
                "level_high": 32767
            },
            "q8_a": {
                "bits": 8,
                "mode": "symmetric",
                "granularity": "pertensor",
                "level_low": -127,
                "level_high": 127
            },
            "q8_w": {
                "bits": 8,
                "mode": "symmetric",
                "granularity": "perchannel",
                "level_low": -127,
                "level_high": 127
            },
            "q16_w": {
                "bits": 16,
                "mode": "symmetric",
                "granularity": "pertensor",
                "level_low": -32767,
                "level_high": 32767
            },
            "q32_o": {
                "bits": 32,
                "mode": "symmetric",
                "granularity": "pertensor",
                "level_low": -2147483648,
                "level_high": 2147483647
            },
            "q16_o": {
                "bits": 16,
                "mode": "symmetric",
                "granularity": "pertensor",
                "level_low": -32768,
                "level_high": 32767
            }
        }
    },
    "operations": [
        {
            "type": "Convolution",
            "quantization": {
                "activations": ["q8_a", "q16_a"],
                "weights": ["q8_w", "q16_w"],
                "outputs": "q32_o"
            }
        },
        {
            "type": "MatMul",
            "quantization": {
                "activations": "q16_a",
                "weights": ["q8_w", "q16_w"],
                "outputs": "q32_o"
            }
        },
        {
            "type": "Add",
            "quantization": {
                "activations": "q16_a",
                "weights": "q16_w",
                "outputs": "q32_o"
            }
        },
        {
            "type": "Subtract",
            "quantization": {
                "activations": "q16_a",
                "weights": "q16_w",
                "outputs": "q32_o"
            }
        },
        {
            "type": "Multiply",
            "quantization": {
                "activations": "q16_a",
                "weights": ["q8_w", "q16_w"],
                "outputs": "q32_o"
            }
        },
        {
            "type": "Power",
            "quantization": {
                "activations": "q32_a",
                "outputs": "q16_o"
            }
        },
        {
            "type": "AvgPool",
            "quantization": {
                "activations": "q16_a"
            }
        },
        {
            "type": "ReduceMean",
            "quantization": {
                "activations": "q16_a"
            }
        },
        {
            "type": "Assign",
            "quantization": {
                "activations": "q16_a"
            }
        },
        {
            "type": "Sigmoid",
            "quantization": {
                "activations": "q32_a",
                "outputs": "q16_o"
            }
        },
        {
            "type": "Tanh",
            "quantization": {
                "activations": "q32_a",
                "outputs": "q16_o"
            }
        },
        {
            "type": "ReLU",
            "quantization": {
                "activations": "q32_a",
                "outputs": "q16_o"
            }
        },
        {
            "type": "PReLU",
            "quantization": {
                "activations": "q32_a",
                "outputs": "q16_o"
            }
        },
        {
            "type": "Clamp",
            "quantization": {
                "activations": "q32_a",
                "outputs": "q16_o"
            }
        },
        {
            "type": "Log",
            "quantization": {
                "activations": "q32_a",
                "outputs": "q16_o"
            }
        },
        {
            "type": "Abs",
            "quantization": {
                "activations": "q32_a",
                "outputs": "q16_o"
            }
        },
        {
            "type": "Exp",
            "quantization": {
                "activations": "q32_a",
                "outputs": "q16_o"
            }
        },
        {
            "type": "Sign",
            "quantization": {
                "activations": "q32_a",
                "outputs": "q16_o"
            }
        },
        {
            "type": "SoftSign",
            "quantization": {
                "activations": "q32_a",
                "outputs": "q16_o"
            }
        },
        {
            "type": "Result",
            "quantization": {
                "activations": "q16_a"
            }
        },
        {
            "type": "Parameter",
            "quantization": {
                "outputs": "q16_o"
            }
        },
        {"type": "MaxPool"},
        {"type": "ReduceMax"},
        {"type": "Reshape"},
        {"type": "Concat"},
        {"type": "Flatten"},
        {"type": "Squeeze"},
        {"type": "Unsqueeze"},
        {"type": "Split"},
        {"type": "VariadicSplit"},
        {"type": "Crop"},
        {"type": "Transpose"},
        {"type": "Tile"},
        {"type": "StridedSlice"},
        {"type": "ShuffleChannels"},
        {"type": "Broadcast"},
        {"type": "Pad"},
        {"type": "ConvertLike"}, 
        {"type": "DepthToSpace"}
    ]
}
