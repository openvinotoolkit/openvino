<?xml version="1.0"?>
<attributes>
    <models>
        # values from {"commit_id": "12d731e59266e19e97b69406db359cb9541bc010", "commit_date": "2021-09-17 11:44"} and *= 1.3
        <!--Models with FP32 precision-->
        <model path="public/mobilenet-ssd/FP32/mobilenet-ssd.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="819504" vmpeak="819504" vmrss="103740" vmhwm="103740" />
        <model path="public/mobilenet-ssd/FP32/mobilenet-ssd.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="1583712" vmpeak="1607387" vmrss="498170" vmhwm="771976" />
        <model path="public/mobilenet-ssd/FP32/mobilenet-ssd.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="994255" vmpeak="1035720" vmrss="155506" vmhwm="155506" />
        <model path="public/mobilenet-ssd/FP32/mobilenet-ssd.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="1784421" vmpeak="1869618" vmrss="501581" vmhwm="754634" />
        <model path="public/mobilenet-ssd/FP32/mobilenet-ssd.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="820887" vmpeak="820887" vmrss="114363" vmhwm="114363" />
        <model path="public/mobilenet-ssd/FP32/mobilenet-ssd.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="1667380" vmpeak="1667380" vmrss="472123" vmhwm="753719" />

        <model path="public/mtcnn/mtcnn-r/FP32/mtcnn-r.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="908018" vmpeak="908018" vmrss="41142" vmhwm="41142" />
        <model path="public/mtcnn/mtcnn-r/FP32/mtcnn-r.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2108095" vmpeak="2230602" vmrss="235618" vmhwm="301486" />
        <model path="public/mtcnn/mtcnn-r/FP32/mtcnn-r.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="1008342" vmpeak="1093008" vmrss="43602" vmhwm="43602" />
        <model path="public/mtcnn/mtcnn-r/FP32/mtcnn-r.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2203952" vmpeak="2241272" vmrss="244328" vmhwm="300103" />
        <model path="public/mtcnn/mtcnn-r/FP32/mtcnn-r.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="908549" vmpeak="908549" vmrss="43492" vmhwm="43492" />
        <model path="public/mtcnn/mtcnn-r/FP32/mtcnn-r.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2108100" vmpeak="2230612" vmrss="223996" vmhwm="300550" />

        <model path="public/ssd300/FP32/ssd300.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="1054892" vmpeak="1054892" vmrss="292962" vmhwm="292962" />
        <model path="public/ssd300/FP32/ssd300.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="1887948" vmpeak="1925471" vmrss="792849" vmhwm="1081917" />
        <model path="public/ssd300/FP32/ssd300.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="1573000" vmpeak="1574372" vmrss="506974" vmhwm="506974" />
        <model path="public/ssd300/FP32/ssd300.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2186204" vmpeak="2271401" vmrss="904259" vmhwm="1060805" />
        <model path="public/ssd300/FP32/ssd300.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="1063322" vmpeak="1063322" vmrss="357931" vmhwm="357931" />
        <model path="public/ssd300/FP32/ssd300.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="1976213" vmpeak="2061410" vmrss="780624" vmhwm="1061335" />

        <model path="public/vgg16/FP32/vgg16.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="2054364" vmpeak="2054364" vmrss="1331959" vmhwm="1331959" />
        <model path="public/vgg16/FP32/vgg16.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2974961" vmpeak="3641424" vmrss="1749748" vmhwm="2555014" />
        <model path="public/vgg16/FP32/vgg16.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="3079637" vmpeak="3079637" vmrss="2074482" vmhwm="2074482" />
        <model path="public/vgg16/FP32/vgg16.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="3217801" vmpeak="3738118" vmrss="1811082" vmhwm="2535015" />
        <model path="public/vgg16/FP32/vgg16.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="2054764" vmpeak="2054764" vmrss="1365842" vmhwm="1365842" />
        <model path="public/vgg16/FP32/vgg16.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="3063273" vmpeak="3641591" vmrss="1777734" vmhwm="2582034" />

        <!--Models with FP16 precision-->
        <model path="public/mobilenet-ssd/FP16/mobilenet-ssd.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="833133" vmpeak="833133" vmrss="118128" vmhwm="118128" />
        <model path="public/mobilenet-ssd/FP16/mobilenet-ssd.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="1535476" vmpeak="1566052" vmrss="462410" vmhwm="789001" />
        <model path="public/mobilenet-ssd/FP16/mobilenet-ssd.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="1007588" vmpeak="1008961" vmrss="168225" vmhwm="168225" />
        <model path="public/mobilenet-ssd/FP16/mobilenet-ssd.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="1727902" vmpeak="1813099" vmrss="469164" vmhwm="764197" />
        <model path="public/mobilenet-ssd/FP16/mobilenet-ssd.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="834516" vmpeak="834516" vmrss="128102" vmhwm="128102" />
        <model path="public/mobilenet-ssd/FP16/mobilenet-ssd.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="1623206" vmpeak="1708402" vmrss="459144" vmhwm="762455" />

        <model path="public/mtcnn/mtcnn-r/FP16/mtcnn-r.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="908169" vmpeak="908169" vmrss="42021" vmhwm="42021" />
        <model path="public/mtcnn/mtcnn-r/FP16/mtcnn-r.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2107846" vmpeak="2145161" vmrss="236984" vmhwm="303448" />
        <model path="public/mtcnn/mtcnn-r/FP16/mtcnn-r.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="1008113" vmpeak="1088786" vmrss="44028" vmhwm="44028" />
        <model path="public/mtcnn/mtcnn-r/FP16/mtcnn-r.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2203697" vmpeak="2222500" vmrss="237996" vmhwm="303904" />
        <model path="public/mtcnn/mtcnn-r/FP16/mtcnn-r.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="908700" vmpeak="908700" vmrss="43227" vmhwm="43227" />
        <model path="public/mtcnn/mtcnn-r/FP16/mtcnn-r.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2107846" vmpeak="2145161" vmrss="235248" vmhwm="305996" />

        <model path="public/ssd300/FP16/ssd300.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="1367288" vmpeak="1367288" vmrss="468748" vmhwm="468748" /> # values from {"commit_id": "25c76471d78628aa772f3a7e341ae915bdce6026", "commit_date": "2022-02-23 15:55"}
        <model path="public/ssd300/FP16/ssd300.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="1630569" vmpeak="1752530" vmrss="546364" vmhwm="874426" />
        <model path="public/ssd300/FP16/ssd300.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="1457409" vmpeak="1458782" vmrss="572577" vmhwm="572577" />
        <model path="public/ssd300/FP16/ssd300.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="1856405" vmpeak="1941602" vmrss="578843" vmhwm="872071" />
        <model path="public/ssd300/FP16/ssd300.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="1309838" vmpeak="1386434" vmrss="421626" vmhwm="421626" />
        <model path="public/ssd300/FP16/ssd300.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="1711881" vmpeak="1797078" vmrss="544310" vmhwm="875368" />

        <model path="public/vgg16/FP16/vgg16.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="3264497" vmpeak="3264497" vmrss="2393794" vmhwm="2393794" /> # values from {"commit_id": "25c76471d78628aa772f3a7e341ae915bdce6026", "commit_date": "2022-02-23 15:55"}
        <model path="public/vgg16/FP16/vgg16.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2206724" vmpeak="2551770" vmrss="1023926" vmhwm="1487049" />
        <model path="public/vgg16/FP16/vgg16.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="3430388" vmpeak="3600781" vmrss="2424016" vmhwm="2424016" />
        <model path="public/vgg16/FP16/vgg16.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2408536" vmpeak="2649150" vmrss="1052251" vmhwm="1493044" />
        <model path="public/vgg16/FP16/vgg16.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="3355554" vmpeak="3440221" vmrss="2426278" vmhwm="2426278" /> # values from {"commit_id": "25c76471d78628aa772f3a7e341ae915bdce6026", "commit_date": "2022-02-23 15:55"}
        <model path="public/vgg16/FP16/vgg16.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2292227" vmpeak="2549414" vmrss="1002950" vmhwm="1461891" />

        <!--Models with FP16-INT8 precision-->
        <model path="intel/face-detection-adas-0001/FP16-INT8/face-detection-adas-0001.xml" precision="FP16-INT8" test="create_exenetwork" device="CPU" vmsize="774961" vmpeak="774961" vmrss="57798" vmhwm="57798" />
        <model path="intel/face-detection-adas-0001/FP16-INT8/face-detection-adas-0001.xml" precision="FP16-INT8" test="create_exenetwork" device="GPU" vmsize="1570218" vmpeak="1570888" vmrss="597532" vmhwm="950341" />
        <model path="intel/face-detection-adas-0001/FP16-INT8/face-detection-adas-0001.xml" precision="FP16-INT8" test="inference_with_streams" device="CPU" vmsize="929905" vmpeak="933842" vmrss="82050" vmhwm="82050" />
        <model path="intel/face-detection-adas-0001/FP16-INT8/face-detection-adas-0001.xml" precision="FP16-INT8" test="inference_with_streams" device="GPU" vmsize="1793214" vmpeak="1878411" vmrss="634275" vmhwm="947356" />
        <model path="intel/face-detection-adas-0001/FP16-INT8/face-detection-adas-0001.xml" precision="FP16-INT8" test="infer_request_inference" device="CPU" vmsize="778887" vmpeak="778887" vmrss="65764" vmhwm="65764" />
        <model path="intel/face-detection-adas-0001/FP16-INT8/face-detection-adas-0001.xml" precision="FP16-INT8" test="infer_request_inference" device="GPU" vmsize="1656538" vmpeak="1741734" vmrss="615196" vmhwm="948500" />

        <model path="intel/person-detection-action-recognition-0006/FP16-INT8/person-detection-action-recognition-0006.xml" precision="FP16-INT8" test="create_exenetwork" device="CPU" vmsize="923795" vmpeak="923795" vmrss="116974" vmhwm="116974" />
        <model path="intel/person-detection-action-recognition-0006/FP16-INT8/person-detection-action-recognition-0006.xml" precision="FP16-INT8" test="create_exenetwork" device="GPU" vmsize="2667496" vmpeak="2687729" vmrss="1880944" vmhwm="2145462" />
        <model path="intel/person-detection-action-recognition-0006/FP16-INT8/person-detection-action-recognition-0006.xml" precision="FP16-INT8" test="inference_with_streams" device="CPU" vmsize="1197664" vmpeak="1201808" vmrss="170669" vmhwm="170669" />
        <model path="intel/person-detection-action-recognition-0006/FP16-INT8/person-detection-action-recognition-0006.xml" precision="FP16-INT8" test="inference_with_streams" device="GPU" vmsize="2887528" vmpeak="2972725" vmrss="1921098" vmhwm="2134969" />
        <model path="intel/person-detection-action-recognition-0006/FP16-INT8/person-detection-action-recognition-0006.xml" precision="FP16-INT8" test="infer_request_inference" device="CPU" vmsize="927945" vmpeak="927945" vmrss="125959" vmhwm="125959" />
        <model path="intel/person-detection-action-recognition-0006/FP16-INT8/person-detection-action-recognition-0006.xml" precision="FP16-INT8" test="infer_request_inference" device="GPU" vmsize="2751954" vmpeak="2751954" vmrss="1885722" vmhwm="2143528" />

        <model path="intel/single-image-super-resolution-1032/FP16-INT8/single-image-super-resolution-1032.xml" precision="FP16-INT8" test="create_exenetwork" device="CPU" vmsize="928678" vmpeak="928678" vmrss="70532" vmhwm="70532" />
        <model path="intel/single-image-super-resolution-1032/FP16-INT8/single-image-super-resolution-1032.xml" precision="FP16-INT8" test="create_exenetwork" device="GPU" vmsize="2702263" vmpeak="2702263" vmrss="907878" vmhwm="907878" /> # values from {"commit_id": "e919bcf91466771a461de300b8eec06cf565e575", "commit_date": "2022-02-10 11:38"} and *= 1.3
        <model path="intel/single-image-super-resolution-1032/FP16-INT8/single-image-super-resolution-1032.xml" precision="FP16-INT8" test="inference_with_streams" device="CPU" vmsize="1305746" vmpeak="1370912" vmrss="338520" vmhwm="338561" />
        <model path="intel/single-image-super-resolution-1032/FP16-INT8/single-image-super-resolution-1032.xml" precision="FP16-INT8" test="inference_with_streams" device="GPU" vmsize="3564912" vmpeak="3564912" vmrss="1653038" vmhwm="1653038" /> # values from {"commit_id": "e919bcf91466771a461de300b8eec06cf565e575", "commit_date": "2022-02-10 11:38"} and *= 1.3
        <model path="intel/single-image-super-resolution-1032/FP16-INT8/single-image-super-resolution-1032.xml" precision="FP16-INT8" test="infer_request_inference" device="CPU" vmsize="993844" vmpeak="993844" vmrss="301698" vmhwm="301698" />
        <model path="intel/single-image-super-resolution-1032/FP16-INT8/single-image-super-resolution-1032.xml" precision="FP16-INT8" test="infer_request_inference" device="GPU" vmsize="2827546" vmpeak="2827546" vmrss="1030224" vmhwm="1030224" /> # values from {"commit_id": "e919bcf91466771a461de300b8eec06cf565e575", "commit_date": "2022-02-10 11:38"} and *= 1.3

        <model path="intel/vehicle-attributes-recognition-barrier-0039/FP16-INT8/vehicle-attributes-recognition-barrier-0039.xml" precision="FP16-INT8" test="create_exenetwork" device="CPU" vmsize="722924" vmpeak="722924" vmrss="37622" vmhwm="37622" />
        <model path="intel/vehicle-attributes-recognition-barrier-0039/FP16-INT8/vehicle-attributes-recognition-barrier-0039.xml" precision="FP16-INT8" test="create_exenetwork" device="GPU" vmsize="1498146" vmpeak="1521130" vmrss="244857" vmhwm="411824" />
        <model path="intel/vehicle-attributes-recognition-barrier-0039/FP16-INT8/vehicle-attributes-recognition-barrier-0039.xml" precision="FP16-INT8" test="inference_with_streams" device="CPU" vmsize="829342" vmpeak="829342" vmrss="39280" vmhwm="39280" />
        <model path="intel/vehicle-attributes-recognition-barrier-0039/FP16-INT8/vehicle-attributes-recognition-barrier-0039.xml" precision="FP16-INT8" test="inference_with_streams" device="GPU" vmsize="1679298" vmpeak="1679298" vmrss="247187" vmhwm="410430" />
        <model path="intel/vehicle-attributes-recognition-barrier-0039/FP16-INT8/vehicle-attributes-recognition-barrier-0039.xml" precision="FP16-INT8" test="infer_request_inference" device="CPU" vmsize="637728" vmpeak="722924" vmrss="38490" vmhwm="38490" />
        <model path="intel/vehicle-attributes-recognition-barrier-0039/FP16-INT8/vehicle-attributes-recognition-barrier-0039.xml" precision="FP16-INT8" test="infer_request_inference" device="GPU" vmsize="1583514" vmpeak="1668711" vmrss="267857" vmhwm="410779" />
    </models>
</attributes>
