Topology,Precision,Input Size,1st latency (ms),2nd latency (ms),max rss memory,2nd token per sec
gemma-2b-it,INT4-MIXED,32,28.6,17.7,3378,56.50
dolly-v2-3b,INT4-MIXED,32,53.6,18.5,3424.4,54.05
gemma-2b-it,INT4-MIXED,1024,196.7,18.6,3390.2,53.76
dolly-v2-3b,INT4-MIXED,1024,392.5,21,3844.7,47.62
gemma-2b-it,INT8-CW,32,35,28.3,3749.2,35.34
gemma-2b-it,INT8-CW,1024,187.5,29.2,3893.1,34.25
dolly-v2-3b,INT8-CW,32,49.8,30.9,4453,32.36
dolly-v2-3b,INT8-CW,1024,363.7,33,4904.5,30.30
chatglm3-6b,INT4-MIXED,32,49,33.9,5220.1,29.50
flan-t5-xxl,INT4-MIXED,33,61.6,34.9,13722.1,28.65
chatglm3-6b,INT4-MIXED,1024,465.7,36,5222.1,27.78
flan-t5-xxl,INT4-MIXED,1139,223.5,39.1,15435.4,25.58
gpt-j-6b,INT4-MIXED,32,72.4,39.6,5314,25.25
gpt-j-6b,INT4-MIXED,1024,563.9,43.7,6473.2,22.88
zephyr-7b-beta,INT4-MIXED,32,67,48.9,6141.4,20.45
baichuan2-7b-chat,INT4-MIXED,32,65.7,50,6553.6,20.00
zephyr-7b-beta,INT4-MIXED,1024,461,51.6,6114.5,19.38
baichuan2-7b-chat,INT4-MIXED,1024,1605.2,54.4,7411.5,18.38
qwen-7b-chat,INT4-MIXED,32,77.7,58.6,7451.7,17.06
gemma-2b-it,FP16,32,66.9,62.4,6240,16.03
gemma-2b-it,FP16,1024,242,63,6373.7,15.87
qwen-7b-chat,INT4-MIXED,1024,476.6,63,8100.3,15.87
dolly-v2-3b,FP16,32,66,65.1,6938,15.36
chatglm3-6b,INT8-CW,32,78.6,66.2,7591.9,15.11
chatglm3-6b,INT8-CW,1024,430.1,68.6,7526.1,14.58
dolly-v2-3b,FP16,1024,433.2,68.8,7754,14.53
gpt-j-6b,INT8-CW,32,85.9,75.1,7469.5,13.32
gpt-j-6b,INT8-CW,1024,562.3,79.1,8937,12.64