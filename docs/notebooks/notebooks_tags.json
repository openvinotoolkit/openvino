{
    "002-openvino-api": [
        "ONNX",
        "Pytorch",
        "Reshape Model",
        "Torchvision"
    ],
    "101-tensorflow-classification-to-openvino": [
        "Tensorflow"
    ],
    "102-pytorch-onnx-to-openvino": [
        "ONNX",
        "Pytorch",
        "Torchvision"
    ],
    "102-pytorch-to-openvino": [
        "Pytorch",
        "Torchvision"
    ],
    "103-paddle-to-openvino-classification": [
        "Paddle"
    ],
    "104-model-tools": [
        "Benchmark Model",
        "Convert Model",
        "Download Model",
        "OMZ Info Dumper",
        "ONNX"
    ],
    "105-language-quantize-bert": [
        "Benchmark Model",
        "NNCF",
        "Pytorch",
        "Transformers"
    ],
    "106-auto-device": [
        "Async Inference",
        "Pytorch",
        "Torchvision"
    ],
    "107-speech-recognition-quantization-data2vec": [
        "Benchmark Model",
        "NNCF",
        "Pytorch",
        "Transformers"
    ],
    "107-speech-recognition-quantization-wav2vec2": [
        "Benchmark Model",
        "NNCF",
        "Pytorch",
        "Transformers"
    ],
    "108-gpu-device": [
        "Async Inference",
        "Benchmark Model",
        "Optimize Model"
    ],
    "109-latency-tricks": [
        "Benchmark Model",
        "ONNX",
        "Pytorch"
    ],
    "109-throughput-tricks": [
        "Async Inference",
        "Benchmark Model",
        "ONNX",
        "Pytorch"
    ],
    "110-ct-scan-live-inference": [
        "Async Inference",
        "Benchmark Model"
    ],
    "110-ct-segmentation-quantize-nncf": [
        "Benchmark Model",
        "NNCF",
        "ONNX",
        "Pytorch"
    ],
    "112-pytorch-post-training-quantization-nncf": [
        "Benchmark Model",
        "NNCF",
        "Pytorch",
        "Torchvision"
    ],
    "113-image-classification-quantization": [
        "Benchmark Model",
        "NNCF",
        "Pytorch",
        "Torchvision"
    ],
    "115-async-api": [
        "Async Inference",
        "Download Model"
    ],
    "116-sparsity-optimization": [
        "Benchmark Model",
        "Transformers"
    ],
    "117-model-server": [
        "ONNX"
    ],
    "118-optimize-preprocessing": [
        "Tensorflow"
    ],
    "119-tflite-to-openvino": [
        "Benchmark Model"
    ],
    "121-convert-to-openvino": [
        "Dynamic Shape",
        "ONNX",
        "Pytorch",
        "Tensorflow",
        "Torchvision",
        "Transformers"
    ],
    "121-legacy-mo-convert-to-openvino": [
        "ONNX",
        "Pytorch",
        "Torchvision",
        "Transformers"
    ],
    "122-speech-recognition-quantization-wav2vec2": [
        "NNCF",
        "Pytorch",
        "Transformers"
    ],
    "122-yolov8-quantization-with-accuracy-control": [
        "Benchmark Model",
        "NNCF",
        "Pytorch"
    ],
    "123-detectron2-to-openvino": [
        "Pytorch"
    ],
    "124-hugging-face-hub": [
        "Pytorch",
        "Transformers"
    ],
    "125-convnext-classification": [
        "Pytorch",
        "Torchvision"
    ],
    "125-lraspp-segmentation": [
        "Pytorch",
        "Torchvision"
    ],
    "126-tensorflow-hub": [
        "Tensorflow"
    ],
    "127-tensorflow-bit-image-classification-nncf-quantization": [
        "NNCF",
        "Reshape Model",
        "Tensorflow",
        "Train Model"
    ],
    "203-meter-reader": [
        "Dynamic Shape",
        "Reshape Model"
    ],
    "204-segmenter-semantic-segmentation": [
        "Benchmark Model",
        "Pytorch",
        "Torchvision"
    ],
    "205-vision-background-removal": [
        "Pytorch"
    ],
    "206-vision-paddlegan-anime": [
        "ONNX",
        "Paddle"
    ],
    "207-vision-paddlegan-superresolution": [
        "ONNX",
        "Paddle"
    ],
    "208-optical-character-recognition": [
        "Convert Model",
        "Download Model",
        "ONNX"
    ],
    "210-slowfast-video-recognition": [
        "Pytorch"
    ],
    "211-speech-to-text": [
        "Convert Model",
        "Download Model",
        "Dynamic Shape",
        "Pytorch",
        "Reshape Model"
    ],
    "212-pyannote-speaker-diarization": [
        "ONNX",
        "Pytorch"
    ],
    "214-grammar-correction": [
        "Async Inference",
        "Transformers"
    ],
    "216-attention-center": [
        "Tensorflow"
    ],
    "219-knowledge-graphs-conve": [
        "Benchmark Model",
        "Pytorch"
    ],
    "220-cross-lingual-books-alignment": [
        "Async Inference",
        "Pytorch",
        "Transformers"
    ],
    "222-vision-image-colorization": [
        "Convert Model",
        "Download Model"
    ],
    "223-text-prediction": [
        "Dynamic Shape",
        "Pytorch",
        "Transformers"
    ],
    "224-3D-segmentation-point-clouds": [
        "Dynamic Shape",
        "ONNX"
    ],
    "225-stable-diffusion-text-to-image": [
        "Pytorch",
        "Transformers"
    ],
    "226-yolov7-optimization": [
        "Benchmark Model",
        "NNCF",
        "ONNX",
        "Pytorch"
    ],
    "227-whisper-convert": [
        "Pytorch"
    ],
    "227-whisper-nncf-quantize": [
        "Benchmark Model",
        "NNCF",
        "Pytorch",
        "Transformers"
    ],
    "228-clip-zero-shot-convert": [
        "Transformers"
    ],
    "228-clip-zero-shot-quantize": [
        "Benchmark Model",
        "NNCF",
        "Pytorch",
        "Transformers"
    ],
    "229-distilbert-sequence-classification": [
        "Pytorch",
        "Transformers"
    ],
    "230-yolov8-instance-segmentation": [
        "Benchmark Model",
        "NNCF",
        "Pytorch",
        "Reshape Model"
    ],
    "230-yolov8-keypoint-detection": [
        "Benchmark Model",
        "NNCF",
        "Pytorch",
        "Reshape Model"
    ],
    "230-yolov8-object-detection": [
        "Benchmark Model",
        "NNCF",
        "Pytorch",
        "Reshape Model"
    ],
    "231-instruct-pix2pix-image-editing": [
        "Benchmark Model",
        "NNCF",
        "Pytorch",
        "Transformers"
    ],
    "232-clip-language-saliency-map": [
        "Async Inference",
        "Pytorch",
        "Transformers"
    ],
    "233-blip-convert": [
        "Pytorch",
        "Transformers"
    ],
    "233-blip-optimize": [
        "Benchmark Model",
        "NNCF",
        "Pytorch",
        "Transformers"
    ],
    "234-encodec-audio-compression": [
        "Pytorch"
    ],
    "235-controlnet-stable-diffusion": [
        "Pytorch",
        "Reshape Model",
        "Transformers"
    ],
    "236-stable-diffusion-v2-infinite-zoom": [
        "Pytorch",
        "Transformers"
    ],
    "236-stable-diffusion-v2-optimum-demo-comparison": [
        "ONNX"
    ],
    "236-stable-diffusion-v2-text-to-image-demo": [
        "Transformers"
    ],
    "236-stable-diffusion-v2-text-to-image": [
        "Pytorch",
        "Transformers"
    ],
    "237-segment-anything": [
        "Benchmark Model",
        "NNCF",
        "Pytorch",
        "Torchvision"
    ],
    "238-deep-floyd-if-convert": [
        "Pytorch",
        "Reshape Model"
    ],
    "238-deep-floyd-if-optimize": [
        "Benchmark Model",
        "NNCF",
        "Pytorch",
        "Reshape Model"
    ],
    "239-image-bind-convert": [
        "Pytorch"
    ],
    "239-image-bind-quantize": [
        "Benchmark Model",
        "NNCF",
        "Pytorch"
    ],
    "240-dolly-2-instruction-following": [
        "Transformers"
    ],
    "241-riffusion-text-to-music": [
        "Pytorch",
        "Transformers"
    ],
    "242-freevc-voice-conversion": [
        "ONNX",
        "Pytorch"
    ],
    "244-named-entity-recognition": [
        "Transformers"
    ],
    "245-typo-detector": [
        "Transformers"
    ],
    "246-depth-estimation-videpth": [
        "Pytorch",
        "Torchvision"
    ],
    "247-code-language-id": [
        "ONNX",
        "Transformers"
    ],
    "248-segmind-vegart": [
        "Benchmark Model",
        "NNCF",
        "Pytorch",
        "Transformers"
    ],
    "248-ssd-b1": [
        "Pytorch"
    ],
    "248-stable-diffusion-xl": [
        "Transformers"
    ],
    "249-oneformer-segmentation": [
        "NNCF",
        "Pytorch",
        "Transformers"
    ],
    "250-music-generation": [
        "Pytorch",
        "Transformers"
    ],
    "251-tiny-sd-image-generation": [
        "Pytorch",
        "Transformers"
    ],
    "252-fastcomposer-image-generation": [
        "Pytorch",
        "Torchvision",
        "Transformers"
    ],
    "253-zeroscope-text2video": [
        "Pytorch",
        "Transformers"
    ],
    "254-llm-chatbot": [
        "NNCF",
        "Pytorch",
        "Transformers"
    ],
    "254-rag-chatbot": [
        "Async Inference",
        "NNCF",
        "Pytorch",
        "Transformers"
    ],
    "255-mms-massively-multilingual-speech": [
        "NNCF",
        "Pytorch",
        "Transformers"
    ],
    "256-bark-text-to-audio": [
        "Dynamic Shape",
        "Pytorch"
    ],
    "257-llava-multimodal-chatbot": [
        "Async Inference",
        "NNCF",
        "Pytorch",
        "Transformers"
    ],
    "257-videollava-multimodal-chatbot": [
        "Async Inference",
        "NNCF",
        "Pytorch",
        "Transformers"
    ],
    "258-blip-diffusion-subject-generation": [
        "Dynamic Shape",
        "Pytorch"
    ],
    "259-decidiffusion-image-generation": [
        "Benchmark Model",
        "NNCF",
        "Pytorch",
        "Transformers"
    ],
    "260-pix2struct-docvqa": [
        "Async Inference",
        "Transformers"
    ],
    "261-fast-segment-anything": [
        "NNCF",
        "ONNX",
        "Pytorch"
    ],
    "262-softvc-voice-conversion": [
        "Pytorch"
    ],
    "263-latent-consistency-models-image-generation": [
        "Benchmark Model",
        "NNCF",
        "Pytorch",
        "Transformers"
    ],
    "263-lcm-lora-controlnet": [
        "Benchmark Model",
        "NNCF",
        "Pytorch",
        "Transformers"
    ],
    "264-qrcode-monster": [
        "Benchmark Model",
        "NNCF",
        "Pytorch",
        "Transformers"
    ],
    "265-wuerstchen-image-generation": [
        "Benchmark Model",
        "NNCF",
        "Pytorch",
        "Transformers"
    ],
    "266-speculative-sampling": [
        "Pytorch",
        "Transformers"
    ],
    "267-distil-whisper-asr": [
        "Async Inference",
        "NNCF",
        "Transformers"
    ],
    "268-table-question-answering": [
        "Pytorch",
        "Transformers"
    ],
    "269-film-slowmo": [
        "Tensorflow"
    ],
    "270-sound-generation-audioldm2": [
        "Pytorch"
    ],
    "271-sdxl-turbo": [
        "Benchmark Model",
        "NNCF",
        "Pytorch",
        "Transformers"
    ],
    "272-paint-by-example": [
        "Pytorch",
        "Transformers"
    ],
    "273-stable-zephyr-3b-chatbot": [
        "Pytorch",
        "Transformers"
    ],
    "274-efficient-sam": [
        "Benchmark Model",
        "NNCF",
        "Pytorch"
    ],
    "275-llm-question-answering": [
        "NNCF",
        "Transformers"
    ],
    "276-stable-diffusion-torchdynamo-backend": [
        "Pytorch"
    ],
    "277-amused-lightweight-text-to-image": [
        "Pytorch"
    ],
    "278-stable-diffusion-ip-adapter": [
        "Pytorch",
        "Transformers"
    ],
    "279-mobilevlm-language-assistant": [
        "Async Inference",
        "NNCF",
        "Pytorch",
        "Transformers"
    ],
    "280-depth-anything": [
        "Pytorch",
        "Torchvision"
    ],
    "281-kosmos2-multimodal-large-language-model": [
        "Async Inference",
        "Pytorch",
        "Transformers"
    ],
    "282-siglip-zero-shot-image-classification": [
        "Benchmark Model",
        "NNCF",
        "Pytorch",
        "Transformers"
    ],
    "283-photo-maker": [
        "Pytorch"
    ],
    "284-openvoice": [
        "Pytorch"
    ],
    "301-tensorflow-training-openvino-nncf": [
        "Benchmark Model",
        "NNCF",
        "Tensorflow"
    ],
    "301-tensorflow-training-openvino": [
        "Tensorflow",
        "Train Model"
    ],
    "302-pytorch-quantization-aware-training": [
        "Benchmark Model",
        "NNCF",
        "Pytorch",
        "Torchvision",
        "Train Model"
    ],
    "305-tensorflow-quantization-aware-training": [
        "Benchmark Model",
        "NNCF",
        "Tensorflow",
        "Train Model"
    ],
    "401-object-detection": [
        "Optimize Model"
    ],
    "402-pose-estimation": [
        "Dynamic Shape"
    ],
    "404-style-transfer": [
        "ONNX"
    ],
    "405-paddle-ocr-webcam": [
        "Dynamic Shape",
        "Paddle",
        "Reshape Model"
    ],
    "406-3D-pose-estimation": [
        "Convert Model",
        "Download Model",
        "ONNX"
    ],
    "407-person-tracking": [
        "Download Model",
        "Dynamic Shape",
        "Reshape Model"
    ]
}
