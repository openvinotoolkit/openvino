# 模型下载程序和其他自动化工具

Open Model Zoo 自动化工具包含脚本，可根据模型目录中的配置文件自动执行某些模型相关任务。

* 模型下载程序：`omz_downloader` 从在线来源下载模型文件，并在必要时进行修补以使其更适用于模型优化器；

* 模型转换器：`omz_converter` 使用模型优化器将不属于 OpenVINO™ IR 格式的模型转换为该格式。

* 模型量化器：`omz_quantizer` 使用训练后优化工具套件，将 IR 格式的全精度模型量化为低精度版本。

* 模型信息转储器：`omz_info_dumper` 以稳定的机器可读格式打印有关模型的信息。

* 数据集的数据下载程序：`omz_data_downloader` 从安装位置复制数据集的数据。

请使用这些工具而不是尝试直接解析配置文件。它们的格式没有记录，并且可能会在未来版本中以不兼容的方式更改。

> **TIP**: 您还可以使用 OpenVINO™ [深度学习工作台](@ref workbench_docs_Workbench_DG_Introduction_zh_CN)中的模型下载程序。
> [深度学习工作台](@ref workbench_docs_Workbench_DG_Introduction_zh_CN)是一个基于 OpenVINO™ 构建的平台，它提供基于 Web 的图形环境，可帮助您对深度学习模型在各种英特尔® 架构配置上的性能进行优化、调优、分析、可视化和比较。在深度学习工作台中，您可以使用大多数 OpenVINO™ 工具套件组件。
> <br>
> 继续[从 Docker 轻松安装](@ref workbench_docs_Workbench_DG_Run_Locally)以开始。

## 安装

模型下载程序和其他自动化工具可以作为 OpenVINO™ 开发工具 Python 程序包的一部分进行安装，或在需要最新更改时从相关来源进行安装。
如需安装程序包中的工具，请访问 [OpenVINO™ 开发工具 PyPI 页面](https://pypi.org/project/openvino-dev/) 并按照说明操作。

如需从相关来源安装工具：

1. 安装 Python（版本 3.6 或更高版本），[安装工具](https://pypi.org/project/setuptools/)：

2. 安装 [openvino-dev](https://pypi.org/project/openvino-dev/) Python 程序包以获取模型优化器和训练后优化工具套件：

```sh
pip install openvino-dev
```
> **NOTE**: openvino-dev 的版本应与 OMZ 工具相同。例如，如果正使用 2021.4.2 版本的 OMZ 工具，则安装 openvino-dev==2021.4.2。

2. 使用以下命令安装工具：

```sh
pip install --upgrade pip
pip install .
```

> **NOTE**: 在 Linux 和 macOS 上，您可能需要键入 `python3` 而不是 `python`。可能还需要[安装 pip](https://pip.pypa.io/en/stable/installation/)。
> 例如，在 Ubuntu 上，请执行以下命令以安装 pip：`sudo apt install python3-pip`。
> 如果使用的 pip 版本低于 21.3，还需要设置 OMZ_ROOT 变量：`export OMZ_ROOT=<omz_dir>`

如需从某些框架转换模型，可能还需要安装其他依赖项。

<!--
@sphinxdirective

.. tab:: PyTorch

  .. code-block:: sh

    python -mpip install --user -r ./requirements-pytorch.in

.. tab:: TensorFlow

  .. code-block:: sh

    python -mpip install --user -r ./requirements-tensorflow.in

.. tab:: PaddlePaddle

  .. code-block:: sh

    python -mpip install --user -r ./requirements-paddle.in

@endsphinxdirective
-->

## 模型下载程序用法

基本用法是像以下方式运行脚本：

```sh
omz_downloader --all
```

这将下载所有模型。`--all` 选项可以用其他筛选选项替代，以仅下载一小部分模型。请参阅“共享选项”部分。

### 模型下载程序起始参数

<!--
@sphinxdirective

+---------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------+
| Parameter                 | Explanation                                                                                                                                                                                                                                                                                                                                                                                      | Example                                                                             |
+===========================+==================================================================================================================================================================================================================================================================================================================================================================================================+=====================================================================================+
| ``-o``/``--output_dir``   | By default, the script will download models into a directory tree rooted in the current directory. Use this parameter to download into a different directory.                                                                                                                                                                                                                                    | ``omz_downloader --all --output_dir my/download/directory``                        |
+---------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------+
| ``--precisions``          | Specify comma separated precisions of weights to be downloaded                                                                                                                                                                                                                                                                                                                                   | ``omz_downloader --name face-detection-retail-0004 --precisions FP16,FP16-INT8``   |
+---------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------+
| ``--num_attempts``        | By default, the script will attempt to download each file only once. Use this parameter to change that and increase the robustness of the download process                                                                                                                                                                                                                                       | ``omz_downloader --all --num_attempts 5 # attempt each download five times``       |
+---------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------+
| ``--cache_dir``           | Make the script use the specified directory as a cache. The script will place a copy of each downloaded file in the cache, or, if it is already there, retrieve it from the cache instead of downloading it again. The cache format is intended to remain compatible in future Open Model Zoo versions, so you can use a cache to avoid redownloading most files when updating Open Model Zoo.   | ``omz_downloader --all --cache_dir my/cache/directory``                            |
+---------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------+
| ``-j``/``--jobs``         | The script downloads files for multiple models concurrently.                                                                                                                                                                                                                                                                                                                                     | ``omz_downloader --all -j8 # download up to 8 models at a time``                   |
+---------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------+
| ``--progress_format``     | By default, the script outputs progress information as unstructured, human-readable text. You can also set this option to `text` to explicitly request the default text format. When this option is set to `json`, the script's standard output is replaced by a machine-readable progress report, whose format is documented in the "JSON progress report format" section. This option does not affect errors and warnings, which will still be printed to the standard error stream in a human-readable format. Use this option, if you want to consume progress information programmatically.                                                                                                                                                                                                                         | ``omz_downloader --all --progress_format=json``                                    |
+---------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------+
@endsphinxdirective
-->

有关脚本接受的其他选项的信息，请参阅“共享选项”部分。

### JSON 进程报告格式

本节记录了在指定了 `--progress_format=json` 选项的情况下，脚本生成的进度报告的格式。

该报告由一系列事件组成。其中每个事件由包含 JSON 编码对象的一行表示。每个事件都有一个名为 `$type` 的成员，其值决定事件的类型，以及其包含的其他成员。

当前定义了以下事件类型：

<!--
@sphinxdirective

+------------------------------------+-------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Event type                         | Additional members                                                      | Explanation                                                                                                                                                                                                                                                                                                                                    |
+====================================+=========================================================================+================================================================================================================================================================================================================================================================================================================================================+
| ``model_download_begin``           | ``model`` (string), ``num_files`` (integer)                             | The script started downloading the model named by ``model``. ``num_files`` is the number of files that will be downloaded for this model. This event will always be followed by a corresponding ``model_download_end`` event.                                                                                                                  |
+------------------------------------+-------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``model_download_end``             | ``model`` (string), ``successful`` (boolean)                            | The script stopped downloading the model named by ``model``. ``successful`` is true if every file was downloaded successfully.                                                                                                                                                                                                                 |
+------------------------------------+-------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``model_file_download_begin``      | ``model`` (string), ``model_file`` (string), ``size`` (integer)         | The script started downloading the file named by ``model_file`` of the model named by ``model``. ``size`` is the size of the file in bytes. This event will always occur between ``model_download_begin`` and ``model_download_end`` events for the model, and will always be followed by a corresponding ``model_file_download_end`` event.   |
+------------------------------------+-------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``model_file_download_end``        | ``model`` (string), ``model_file`` (string), ``successful`` (boolean)   | The script stopped downloading the file named by ``model_file`` of the model named by ``model``. ``successful`` is true if the file was downloaded successfully.                                                                                                                                                                               |
+------------------------------------+-------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``model_file_download_progress``   | ``model`` (string), ``model_file`` (string), ``size`` (integer)         | The script downloaded ``size`` bytes of the file named by ``model_file`` of the model named by ``model`` so far. Note that ``size`` can decrease in a subsequent event if the download is interrupted and retried. This event will always occur between ``model_file_download_begin`` and ``model_file_download_end`` events for the file.     |
+------------------------------------+-------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``model_postprocessing_begin``     | ``model``                                                               | The script started post-download processing on the model named by ``model``. This event will always be followed by a corresponding ``model_postprocessing_end`` event.                                                                                                                                                                         |
+------------------------------------+-------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``model_postprocessing_end``       | ``model``                                                               | The script stopped post-download processing on the model named by ``model``.                                                                                                                                                                                                                                                                   |
+------------------------------------+-------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
@endsphinxdirective
-->

将来可能会添加其他事件类型和成员。

解析机器可读格式的工具应避免依赖未记录的细节。
特别是：

* 工具不应该假设任何给定的事件都会发生在给定的模型/文件（除非上面另有说明）或只会发生一次。

* 工具不应假设事件会以超出上面指定的顺序约束的特定顺序发生。特别是，如果将 `--jobs` 选项设置为大于 1 的值，不同文件或模型的事件序列可能会交错。

## 模型转换器用法

基本用法是像以下方式运行脚本：

```sh
omz_converter --all
```

这会将所有模型转换为 OpenVINO™ IR 格式。最初采用该格式的模型将被忽略。PyTorch 格式的模型首先会转换为 ONNX 格式。

`--all` 选项可以用其他筛选选项替代，以仅转换一小部分模型。请参阅“共享选项”部分。

### 模型转换器起始参数

<!--
@sphinxdirective

+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+
| Parameter                   | Explanation                                                                                                                                                                                                                                                      | Example                                                                                          |
+=============================+==================================================================================================================================================================================================================================================================+==================================================================================================+
| ``-d``/``--download_dir``   | The current directory must be the root of a download tree created by the model downloader. Use this parameter to specify a different download tree path.                                                                                                         | ``omz_converter --all --download_dir my/download/directory``                                    |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+
| ``-o``/``--output_dir``     | By default, the script will download models into a directory tree rooted in the current directory. Use this parameter to download into a different directory. Note: models in intermediate format are placed to this directory too.                              | ``omz_converter --all --output_dir my/output/directory``                                        |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+
| ``--precisions``            | By default, the script will produce models in every precision that is supported for conversion. Use this parameter to only produce models in a specific precision. If the specified precision is not supported for a model, that model will be skipped.          | ``omz_converter --all --precisions=FP16``                                                       |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+
| ``--add_mo_arg``            | Add extra Model Optimizer arguments to the ones specified in the model configuration. The option can be repeated to add multiple arguments                                                                                                                       | ``omz_converter --name=caffenet --add_mo_arg=--reverse_input_channels --add_mo_arg=--silent``   |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+
| ``-j``/``--jobs``           | Run multiple conversion commands concurrently. The argument to the option must be either a maximum number of concurrently executed commands, or "auto", in which case the number of CPUs in the system is used. By default, all commands are run sequentially.   | ``omz_converter --all -j8 # run up to 8 commands at a time``                                    |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+
| ``--dry_run``               | Print the conversion commands without actually running them..                                                                                                                                                                                                    | ``omz_converter --all --dry_run``                                                               |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+
| ``-p``/``--python``         | By default, the script will run Model Optimizer using the same Python executable that was used to run the script itself. Apply this parameter to use a different Python executable.                                                                              | ``omz_converter --all --python my/python``                                                      |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+
@endsphinxdirective
-->

该脚本将尝试使用多种方法找到模型优化器：

1. 如果指定了 `--mo` 选项，那么它的值将被用作要运行的脚本的路径：

   ```sh
   omz_converter --all --mo my/openvino/path/model_optimizer/mo.py
   ```

2. 否则，如果选定的 Python 可执行文件可以找到 `mo` 切入点，则会使用该切入点。

3. 否则，如果已执行 OpenVINO&trade; 工具套件的 `setupvars.sh`/`setupvars.bat` 脚本，则会将该脚本设置的环境变量用于在工具套件内查找模型优化器。

4. 否则，脚本将失败。


## 模型量化器使用

在运行模型量化器之前，您必须准备一个包含量化过程所需数据集的目录。在下文中，此目录将被称为 `<DATASET_DIR>`。您可以在[数据集准备指南](../../data/datasets.md)中找到关于数据集准备的更多详细信息。

基本用法是像以下方式运行脚本：

```sh
omz_quantizer --all --dataset_dir <DATASET_DIR>
```

这将量化所有支持量化的模型。其他模型被忽略。

`--all` 选项可以用其他筛选选项替代，以仅量化一小部分模型。请参阅“共享选项”部分。

<!--
@sphinxdirective

+---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+
| Parameter                 | Explanation                                                                                                                                                                                                                                                                                                         | Example                                                                                 |
+===========================+=====================================================================================================================================================================================================================================================================================================================+=========================================================================================+
| ``--model_dir``           | The current directory must be the root of a tree of model files create by the model converter. Use this parameter to specify a different model tree path                                                                                                                                                            | ``omz_quantizer --all --dataset_dir <DATASET_DIR> --model_dir my/model/directory``     |
+---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+
| ``-o``/``--output_dir``   | By default, the script will download models into a directory tree rooted in the current directory. Use this parameter to download into a different directory. Note: models in intermediate format are placed to this directory too.                                                                                 | ``omz_quantizer --all --dataset_dir <DATASET_DIR> --output_dir my/output/directory``   |
+---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+
| ``--precisions``          | By default, the script will produce models in every precision that is supported as a quantization output. Use this parameter to only produce models in a specific precision.                                                                                                                                        | ``omz_quantizer --all --dataset_dir <DATASET_DIR> --precisions=FP16-INT8``             |
+---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+
| ``--target_device``       | It's possible to specify a target device for Post-Training Optimization Toolkitto optimize for. The supported values are those accepted by the "target\_device" option in Post-Training Optimization Toolkit's config files. If this option is unspecified, Post-Training Optimization Toolkit's default is used.   | ``omz_quantizer --all --dataset_dir <DATASET_DIR> --target_device VPU``               |
+---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+
| ``--dry_run``             | The script can print the quantization commands without actually running them. With this option specified, the configuration file for Post-Training Optimization Toolkit will still be created, so that you can inspect it.                                                                                          | ``omz_quantizer --all --dataset_dir <DATASET_DIR> --dry_run``                          |
+---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+
| ``-p``/``--python``       | By default, the script will run Model Optimizer using the same Python executable that was used to run the script itself. Apply this parameter to use a different Python executable.                                                                                                                                 | ``omz_quantizer --all --dataset_dir <DATASET_DIR> --python my/python``                 |
+---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+
@endsphinxdirective
-->

该脚本将尝试使用多种方法找到训练后优化工具套件：

1. 如果指定了 `--pot` 选项，那么它的值将被用作要运行的脚本的路径：

   ```sh
   omz_quantizer --all --dataset_dir <DATASET_DIR> --pot my/openvino/path/post_training_optimization_toolkit/main.py
   ```

2. 否则，如果选定的 Python 可执行文件可以找到 `pot` 切入点，则会使用该切入点。

3. 否则，如果已执行 OpenVINO&trade; 工具套件的 `setupvars.sh`/`setupvars.bat` 脚本，则会将该脚本设置的环境变量用于在 OpenVINO™ 工具套件内查找训练后优化工具套件。

4. 否则，脚本将失败。


## 模型信息转储器用法

基本用法是像以下方式运行脚本：

```sh
omz_info_dumper --all
```

脚本接受的其他选项如“共享选项”一节所述。

这将打印到所有模型的标准输出信息。该脚本的输出是一个 JSON 数组，其中的每个元素都是一个描述单个模型的 JSON 对象。每个这样的对象都有以下键：


<!--
@sphinxdirective

+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Parameter                            | Explanation                                                                                                                                                                                                                                                                         |
+======================================+=====================================================================================================================================================================================================================================================================================+
| ``name``                             | The identifier of the model, as accepted by the ``--name`` option.                                                                                                                                                                                                                  |
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``composite_model_name``             | The identifier of the composite model name, if the model is a part of composition of several models (e.g. encoder-decoder), otherwise - ``null``                                                                                                                                    |
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``description``                      | Text describing the model. Paragraphs are separated by line feed characters.                                                                                                                                                                                                        |
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``framework``                        | A string identifying the framework whose format the model is downloaded in. Current possible values are ``dldt`` (Inference Engine IR), ``caffe``, ``mxnet``, ``onnx``, ``pytorch`` and ``tf`` (TensorFlow). Additional possible values might be added in the future.               |
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``license_url``                      | A URL for the license that the model is distributed under.                                                                                                                                                                                                                          |
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``accuracy_config``                      | Path to the model accuracy config in the user's file system.                                                                                                                                                                                                                          |
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``model_config``                      | Path to the model configuration file in the user's file system.                                                                                                                                                                                                                          |
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``precisions``                       | The list of precisions that the model has IR files for. For models downloaded in a format other than the Inference Engine IR format, these are the precisions that the model converter can produce IR files in. Current possible values are:                                        |
|                                      | * `FP16`                                                                                                                                                                                                                                                                            |
|                                      | * `FP16-INT1`                                                                                                                                                                                                                                                                       |
|                                      | * `FP16-INT8`                                                                                                                                                                                                                                                                       |
|                                      | * `FP32`                                                                                                                                                                                                                                                                            |
|                                      | * `FP32-INT1`                                                                                                                                                                                                                                                                       |
|                                      | * `FP32-INT8`                                                                                                                                                                                                                                                                       |
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``quantization_output_precisions``   | The list of precisions that the model can be quantized to by the model quantizer. Current possible values are ``FP16-INT8`` and ``FP32-INT8``; additional possible values might be added in the future.                                                                             |
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``subdirectory``                     | The subdirectory of the output tree into which the downloaded or converted files will be placed by the downloader or the converter, respectively.                                                                                                                                   |
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``task_type``                        | a string identifying the type of task that the model performs. Current possible values are:                                                                                                                                                                                         |
|                                      |                                                                                                                                                                                                                                                                                     |
|                                      | * `action_recognition`                                                                                                                                                                                                                                                              |
|                                      | * `classification`                                                                                                                                                                                                                                                                  |
|                                      | * `colorization`                                                                                                                                                                                                                                                                    |
|                                      | * `detection`                                                                                                                                                                                                                                                                       |
|                                      | * `face_recognition`                                                                                                                                                                                                                                                                |
|                                      | * `feature_extraction`                                                                                                                                                                                                                                                              |
|                                      | * `head_pose_estimation`                                                                                                                                                                                                                                                            |
|                                      | * `human_pose_estimation`                                                                                                                                                                                                                                                           |
|                                      | * `image_inpainting`                                                                                                                                                                                                                                                                |
|                                      | * `image_processing`                                                                                                                                                                                                                                                                |
|                                      | * `image_translation`                                                                                                                                                                                                                                                               |
|                                      | * `instance_segmentation`                                                                                                                                                                                                                                                           |
|                                      | * `machine_translation`                                                                                                                                                                                                                                                             |
|                                      | * `monocular_depth_estimation`                                                                                                                                                                                                                                                      |
|                                      | * `named_entity_recognition`                                                                                                                                                                                                                                                        |
|                                      | * `noise_suppression`                                                                                                                                                                                                                                                               |
|                                      | * `object_attributes`                                                                                                                                                                                                                                                               |
|                                      | * `optical_character_recognition`                                                                                                                                                                                                                                                   |
|                                      | * `place_recognition`                                                                                                                                                                                                                                                               |
|                                      | * `question_answering`                                                                                                                                                                                                                                                              |
|                                      | * `salient_object_detection`                                                                                                                                                                                                                                                        |
|                                      | * `semantic_segmentation`                                                                                                                                                                                                                                                           |
|                                      | * `sound_classification`                                                                                                                                                                                                                                                            |
|                                      | * `speech_recognition`                                                                                                                                                                                                                                                              |
|                                      | * `style_transfer`                                                                                                                                                                                                                                                                  |
|                                      | * `text_prediction`                                                                                                                                                                                                                                                                 |
|                                      | * `text_to_speech`                                                                                                                                                                                                                                                                  |
|                                      | * `time_series`                                                                                                                                                                                                                                                                     |
|                                      | * `token_recognition`                                                                                                                                                                                                                                                               |
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``input_info``                       | The list of inputs containing the information about input name, shape and layout.                                                                                                                                                                                                   |
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``model_stages``                     | The list of model stages, in case if the model is a composition of several models,  otherwise the list is empty                                                                                                                                                                     |
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
@endsphinxdirective
-->

## 共享选项

这是所有工具都接受的某些选项。

`-h`/`--help` 可以用于打印帮助消息：

```sh
omz_TOOL --help
```
有几个相互排斥的筛选选项可以选择工具将处理的模型：

<!--
@sphinxdirective

+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------+
| Parameter    | Explanation                                                                                                                                                                                                                                                                       | Example                                   |
+==============+===================================================================================================================================================================================================================================================================================+===========================================+
| ``--all``    | Selects all models                                                                                                                                                                                                                                                                | ``omz_TOOL --all``                        |
+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------+
| ``--name``   | takes a comma-separated list of patterns and selects models that match at least one of these patterns. The patterns may contain shell-style wildcards. See https://docs.python.org/3/library/fnmatch.html for a full description of the pattern syntax. For composite models, the name of composite model is accepted, as well as the names of individual models it consists of.   | ``omz_TOOL --name 'mtcnn,densenet-*'``    |
+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------+
| ``--list``   | takes a path to a file that must contain a list of patterns and selects models that match at least one of those patterns. For composite models, the name of composite model is accepted, as well as the names of individual models it consists of                                 | ``omz_TOOL --list my.lst``                |
+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------+
@endsphinxdirective
-->


如需查看可用模型，可以使用 `--print_all` 选项。指定此选项后，该工具将打印配置文件中定义的所有模型名称并退出：

```
$ omz_TOOL --print_all
action-recognition-0001-decoder
action-recognition-0001-encoder
age-gender-recognition-retail-0013
driver-action-recognition-adas-0002-decoder
driver-action-recognition-adas-0002-encoder
emotions-recognition-retail-0003
face-detection-adas-0001
face-detection-retail-0004
face-detection-retail-0005
[...]
```

必须指定 `--print_all` 或其中一个筛选选项。


## 数据集的数据下载程序用法

用法是按如下所示运行脚本：

```sh
omz_data_downloader -o my/output/directory
```

这会将数据集的数据从安装位置复制到指定位置。
如果未设置 `-o`/`--output_dir` 选项，则会将文件复制到以当前目录为根的目录树中。


__________

OpenVINO 是英特尔公司或其子公司在美国和/或其他国家的商标。


版权所有 &copy; 2018-2019，英特尔公司

根据 Apache 许可证，版本 2.0（“许可证”）获得许可；除非遵守许可证，否则您不得使用此文件。
您可以在以下位置获得一份许可证：

     http://www.apache.org/licenses/LICENSE-2.0

除非适用法律要求或书面同意，否则根据许可证分发的软件是按“原样”分发，没有任何类型明示或暗示的保证或条件。
请参阅许可证，了解许可证下适用于权限和限制的特定语言。