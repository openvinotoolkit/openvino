# Performance Benchmarks {#openvino_docs_performance_benchmarks}

The [Intel® Distribution of OpenVINO™ toolkit](https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit.html) helps accelerate deep learning inference across a variety of Intel® processors and accelerators.  

The benchmarks below demonstrate high performance gains on several public neural networks on multiple Intel® CPUs and VPUs covering a broad performance range. Use this data to help you decide which hardware is best for your applications and solutions, or to plan your AI workload on the Intel computing already included in your solutions. 

Use the links below to review the benchmarking results for each alternative: 

* [Intel® Distribution of OpenVINO™ toolkit Benchmark Results](performance_benchmarks_openvino.md)  
* [OpenVINO™ Model Server Benchmark Results](performance_benchmarks_ovms.md)  

