name: PyTorch Models tests

on:
  workflow_call:
    inputs:
      runner:
        description: 'Machine on which the tests would run'
        type: string
        required: true
      container:
        description: 'JSON to be converted to the value of the "container" configuration for the job'
        type: string
        required: false
        default: '{"image": null}'
      model_scope:
        description: 'Scope of models for testing.'
        type: string
        required: true

permissions: read-all

jobs:
  PyTorch_Models_Tests:
    name: PyTorch Models tests
    timeout-minutes: ${{ inputs.model_scope == 'precommit' && 45 || 400 }}
    runs-on: ${{ inputs.runner }}
    container: ${{ fromJSON(inputs.container) }}
    defaults:
      run:
        shell: bash
    env:
      DEBIAN_FRONTEND: noninteractive # to prevent apt-get from waiting user input
      OPENVINO_REPO: ${{ github.workspace }}/openvino
      INSTALL_DIR: ${{ github.workspace }}/install
      INSTALL_TEST_DIR: ${{ github.workspace }}/install/tests
      INSTALL_WHEELS_DIR: ${{ github.workspace }}/install/wheels
      MODEL_HUB_TESTS_INSTALL_DIR: ${{ github.workspace }}/install/tests/model_hub_tests
    steps:
      - name: Check sudo
        if: ${{ runner.os == 'Linux' }}
        run: if [ "$(id -u)" -eq 0 ]; then apt update && apt --assume-yes install sudo; fi

      - name: Set apt retries
        if: runner.os == 'Linux'
        run: |
          if [ "$(id -u)" -eq 0 ]; then
            echo 'Acquire::Retries "10";' > /etc/apt/apt.conf.d/80-retries
          else
            sudo sh -c "echo 'Acquire::Retries \"10\";' >> /etc/apt/apt.conf.d/80-retries"
          fi

      - name: Download OpenVINO artifacts (tarballs)
        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16 # v4.1.8
        with:
          pattern: openvino_[tests]*
          path: ${{ env.INSTALL_DIR }}
          merge-multiple: true
          
      - name: Download OpenVINO artifacts (wheels)
        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16 # v4.1.8
        with:
          pattern: openvino_[wheels|tokenizers_wheel]*
          path: ${{ env.INSTALL_WHEELS_DIR }}
          merge-multiple: true

      # Needed as ${{ github.workspace }} is not working correctly when using Docker
      - name: Setup Variables
        run: |
          echo "OPENVINO_REPO=$GITHUB_WORKSPACE/openvino" >> "$GITHUB_ENV"
          echo "INSTALL_DIR=$GITHUB_WORKSPACE/install" >> "$GITHUB_ENV"
          echo "INSTALL_TEST_DIR=$GITHUB_WORKSPACE/install/tests" >> "$GITHUB_ENV"
          echo "MODEL_HUB_TESTS_INSTALL_DIR=$GITHUB_WORKSPACE/install/tests/model_hub_tests" >> "$GITHUB_ENV"

      - name: Extract OpenVINO artifacts
        run: |
            pigz -dc openvino_tests.tar.gz | tar -xf - -C ${INSTALL_DIR}
        working-directory: ${{ env.INSTALL_DIR }}

      - name: Fetch setup_python action
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          sparse-checkout: |
            .github/actions/setup_python/action.yml
          sparse-checkout-cone-mode: false
          path: 'openvino'

      - name: Install dependencies
        if: ${{ runner.os == 'Linux' }}
        run: |
          # install git (required to build pip deps from the sources)
          # install 'g++' to build 'detectron2' and 'natten' wheels
          sudo apt-get install --assume-yes --no-install-recommends g++ git ca-certificates

      - name: Setup Python 3.11
        uses: ./openvino/.github/actions/setup_python
        with:
          version: '3.11'
          should-setup-pip-paths: 'false'
          self-hosted-runner: ${{ contains(inputs.runner, 'aks') }}

      - name: Install OpenVINO Python wheels
        run: |
          # To enable pytest parallel features
          python3 -m pip install ./openvino-*
          python3 -m pip install ./openvino_tokenizers-*
        working-directory: ${{ env.INSTALL_WHEELS_DIR }}

      - name: Install PyTorch tests requirements
        run: |
          python3 -m pip install -r ${INSTALL_TEST_DIR}/requirements_pytorch
        env:
          CPLUS_INCLUDE_PATH: ${{ env.Python_ROOT_DIR }}/include/python${{ env.PYTHON_VERSION }}

      - name: PyTorch Models Tests Timm and Torchvision
        if: ${{ inputs.model_scope == 'precommit' || inputs.model_scope == 'nightly_scope1' }}
        run: |
          export PYTHONPATH=${MODEL_HUB_TESTS_INSTALL_DIR}:$PYTHONPATH
          python3 -m pytest ${MODEL_HUB_TESTS_INSTALL_DIR}/pytorch/ -m ${TYPE} --html=${INSTALL_TEST_DIR}/TEST-torch_model_timm_tv_${{ inputs.model_scope }}_tests.html --self-contained-html -v -n 4 -k "TestTimmConvertModel or TestTorchHubConvertModel or TestEdsrConvertModel"
        env:
          TYPE: ${{ inputs.model_scope == 'precommit' && 'precommit' || 'nightly' }}
          TEST_DEVICE: CPU
          OP_REPORT_FILE: ${{ env.INSTALL_TEST_DIR }}/TEST-torch_unsupported_ops.log

      - name: PyTorch Models Tests Not Timm or Torchvision
        if: ${{ inputs.model_scope == 'precommit' || inputs.model_scope == 'nightly_scope2' }}
        run: |
          export PYTHONPATH=${MODEL_HUB_TESTS_INSTALL_DIR}:$PYTHONPATH
          python3 -m pytest ${MODEL_HUB_TESTS_INSTALL_DIR}/pytorch -m ${TYPE} --html=${INSTALL_TEST_DIR}/TEST-torch_model_${{ inputs.model_scope }}_tests.html --self-contained-html -v -k "not (TestTimmConvertModel or TestTorchHubConvertModel or TestEdsrConvertModel)"
        env:
          TYPE: ${{ inputs.model_scope == 'precommit' && 'precommit' || 'nightly' }}
          TEST_DEVICE: CPU
          USE_SYSTEM_CACHE: False
          OP_REPORT_FILE: ${{ env.INSTALL_TEST_DIR }}/TEST-torch_unsupported_ops.log

      - name: PagedAttention Test
        if: ${{ inputs.model_scope == 'precommit' }}
        run: |
          export PYTHONPATH=${MODEL_HUB_TESTS_INSTALL_DIR}:$PYTHONPATH
          python3 -m pytest ${MODEL_HUB_TESTS_INSTALL_DIR}/transformation_tests/test_pa_transformation.py -m precommit --html=${INSTALL_TEST_DIR}/TEST-torch_pagedattention_tests.html --self-contained-html -vvv -s --tb=short -n 2
        env:
          TEST_DEVICE: CPU
          USE_SYSTEM_CACHE: False

      - name: RoPE Test
        if: ${{ inputs.model_scope == 'precommit' }}
        run: |
          export PYTHONPATH=${MODEL_HUB_TESTS_INSTALL_DIR}:$PYTHONPATH
          python3 -m pytest ${MODEL_HUB_TESTS_INSTALL_DIR}/transformation_tests/test_transformations.py -m precommit --html=${INSTALL_TEST_DIR}/TEST-torch_rope_tests.html --self-contained-html -v --tb=short -n 2
        env:
          TEST_DEVICE: CPU
          USE_SYSTEM_CACHE: False

      - name: StatefulToStateless Test
        if: ${{ inputs.model_scope == 'precommit' }}
        run: |
          export PYTHONPATH=${MODEL_HUB_TESTS_INSTALL_DIR}:$PYTHONPATH
          python3 -m pytest ${MODEL_HUB_TESTS_INSTALL_DIR}/transformation_tests/test_stateful_to_stateless_transformation.py -m precommit --html=${INSTALL_TEST_DIR}/TEST-torch_stateful_to_stateless_tests.html --self-contained-html -v --tb=short
        env:
          TEST_DEVICE: CPU
          USE_SYSTEM_CACHE: False

      - name: TorchFX GPTQ Pattern Test
        if: ${{ inputs.model_scope == 'precommit' }}
        # install torch 2.3.1 as newer is not yet supported by openvino backend
        run: |
          export PYTHONPATH=${MODEL_HUB_TESTS_INSTALL_DIR}:$PYTHONPATH
          python3 -m pip install torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 --upgrade --index-url https://download.pytorch.org/whl/cpu
          python3 -m pytest ${MODEL_HUB_TESTS_INSTALL_DIR}/transformation_tests/test_gptq_torchfx_transformations.py -m precommit --html=${INSTALL_TEST_DIR}/TEST-torch_gptqpattern_tests.html --self-contained-html -v --tb=short
        env:
          TEST_DEVICE: CPU
          USE_SYSTEM_CACHE: False

      - name: Reformat unsupported ops file
        if: ${{ inputs.model_scope != 'precommit' && !cancelled()}}
        run: |
          python3 ${MODEL_HUB_TESTS_INSTALL_DIR}/pytorch/scripts/process_op_report.py ${INSTALL_TEST_DIR}/TEST-torch_unsupported_ops.log

      - name: Available storage after tests
        run: |
          echo "Available storage:"
          df -h

      - name: Upload Test Results
        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882 # v4.4.3
        if: ${{ !cancelled() }}
        with:
          name: test-results-torch-models-${{ inputs.model_scope }}
          path: |
            ${{ env.INSTALL_TEST_DIR }}/TEST-torch*
          if-no-files-found: 'error'
